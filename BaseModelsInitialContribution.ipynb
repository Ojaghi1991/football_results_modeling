{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUXn2iC2RVFH"
   },
   "source": [
    "# Basic Code on 1991/92 season (To check similarity with paper values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e105886fc1eb4609ba2cc131d9d8221b",
      "cef302dca852422f98157249454bc940",
      "afa1680a220f42a39bea401398a07527",
      "ff3d95299bde4a8f93ff52b347803b07"
     ]
    },
    "id": "ViqykBFpRUy-",
    "outputId": "5acdff81-1ad0-40b0-fbde-c41d689d66d5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BayesianFootballModel:\n",
    "    \"\"\"\n",
    "    Bayesian hierarchical model for football match prediction\n",
    "    Based on Baio & Blangiardo (2010) paper\n",
    "\n",
    "    Combines visualization capabilities and comparison table functionality\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_file):\n",
    "        \"\"\"Initialize the model with data\"\"\"\n",
    "        print(f\"Initializing model with data file: {data_file}\")\n",
    "\n",
    "        # Initialize model attributes first (but not data attributes)\n",
    "        self.basic_model = None\n",
    "        self.mixture_model = None\n",
    "        self.basic_trace = None\n",
    "        self.mixture_trace = None\n",
    "\n",
    "        try:\n",
    "            self.data = self.load_and_prepare_data(data_file)\n",
    "            print(\" Model initialization completed successfully\")\n",
    "            print(f\" Final check - n_games: {self.n_games}, n_teams: {self.n_teams}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error during model initialization: {e}\")\n",
    "            print(\"Please check that the data file exists and has the correct format\")\n",
    "            raise\n",
    "\n",
    "    def load_and_prepare_data(self, data_file):\n",
    "        \"\"\"Load and prepare the football data\"\"\"\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel('/data/dataset/italy_serie-a_1991-1992.xlsx')\n",
    "\n",
    "        # Clean column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "        # Create team mappings\n",
    "        all_teams = pd.concat([\n",
    "            df['home team'],\n",
    "            df['away team']\n",
    "        ]).unique()\n",
    "\n",
    "        team_to_id = {team: i for i, team in enumerate(sorted(all_teams))}\n",
    "        id_to_team = {i: team for team, i in team_to_id.items()}\n",
    "\n",
    "        # Map team names to consecutive IDs (0-based)\n",
    "        df['home_team_idx'] = df['home team'].map(team_to_id)\n",
    "        df['away_team_idx'] = df['away team'].map(team_to_id)\n",
    "\n",
    "        # Check for any mapping issues\n",
    "        if df['home_team_idx'].isna().any() or df['away_team_idx'].isna().any():\n",
    "            print(\"Warning: Some teams could not be mapped!\")\n",
    "            print(\"Home team mapping issues:\", df[df['home_team_idx'].isna()]['home team'].unique())\n",
    "            print(\"Away team mapping issues:\", df[df['away_team_idx'].isna()]['away team'].unique())\n",
    "\n",
    "        # Store team information\n",
    "        self.teams = sorted(all_teams)\n",
    "        self.n_teams = len(self.teams)\n",
    "        self.n_games = len(df)\n",
    "\n",
    "        print(f\"Data loaded: {self.n_games} games, {self.n_teams} teams\")\n",
    "        print(f\"Teams: {self.teams}\")\n",
    "\n",
    "        # Verify no None values\n",
    "        print(f\"n_games type: {type(self.n_games)}, value: {self.n_games}\")\n",
    "        print(f\"n_teams type: {type(self.n_teams)}, value: {self.n_teams}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def build_basic_model(self):\n",
    "        \"\"\"Build the basic hierarchical model from Section 2 of the paper\"\"\"\n",
    "\n",
    "        # Check if data is properly loaded\n",
    "        if self.n_games is None or self.n_teams is None:\n",
    "            raise ValueError(\"Data not properly loaded. Please check the data file and team mappings.\")\n",
    "\n",
    "        print(f\"Building model with {self.n_games} games and {self.n_teams} teams\")\n",
    "\n",
    "        # Prepare data arrays\n",
    "        home_team_idx = self.data['home_team_idx'].values\n",
    "        away_team_idx = self.data['away_team_idx'].values\n",
    "        y1_data = self.data['y1'].values\n",
    "        y2_data = self.data['y2'].values\n",
    "\n",
    "        # Verify data integrity\n",
    "        print(f\"Home team indices range: {home_team_idx.min()} to {home_team_idx.max()}\")\n",
    "        print(f\"Away team indices range: {away_team_idx.min()} to {away_team_idx.max()}\")\n",
    "        print(f\"Goals range - Home: {y1_data.min()} to {y1_data.max()}, Away: {y2_data.min()} to {y2_data.max()}\")\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            # Home advantage parameter\n",
    "            home_advantage = pm.Normal(\"home_advantage\", mu=0, tau=0.0001)\n",
    "\n",
    "            # Hyperparameters for attack and defense effects\n",
    "            mu_att = pm.Normal(\"mu_att\", mu=0, tau=0.0001)\n",
    "            mu_def = pm.Normal(\"mu_def\", mu=0, tau=0.0001)\n",
    "            tau_att = pm.Gamma(\"tau_att\", alpha=0.01, beta=0.01)\n",
    "            tau_def = pm.Gamma(\"tau_def\", alpha=0.01, beta=0.01)\n",
    "\n",
    "            # Team-specific attack and defense effects (before centering)\n",
    "            att_star = pm.Normal(\"att_star\", mu=mu_att, tau=tau_att, shape=self.n_teams)\n",
    "            def_star = pm.Normal(\"def_star\", mu=mu_def, tau=tau_def, shape=self.n_teams)\n",
    "\n",
    "            # Sum-to-zero constraint (centering)\n",
    "            att = pm.Deterministic(\"att\", att_star - pt.mean(att_star))\n",
    "            def_ = pm.Deterministic(\"def\", def_star - pt.mean(def_star))\n",
    "\n",
    "\n",
    "            log_theta_g1 = home_advantage + att[home_team_idx] + def_[away_team_idx]\n",
    "            log_theta_g2 = att[away_team_idx] + def_[home_team_idx]\n",
    "\n",
    "            theta_g1 = pm.Deterministic(\"theta_g1\", pt.exp(log_theta_g1))\n",
    "            theta_g2 = pm.Deterministic(\"theta_g2\", pt.exp(log_theta_g2))\n",
    "\n",
    "            # Likelihood - each game has its own theta values\n",
    "            y1 = pm.Poisson(\"y1\", mu=theta_g1, observed=y1_data)\n",
    "            y2 = pm.Poisson(\"y2\", mu=theta_g2, observed=y2_data)\n",
    "\n",
    "        print(\"Model built successfully!\")\n",
    "        self.basic_model = model\n",
    "        return model\n",
    "\n",
    "    def fit_basic_model(self, draws=2000, tune=1000, chains=3, cores=1):\n",
    "        \"\"\"Fit the basic hierarchical model\"\"\"\n",
    "        print(\"Fitting basic hierarchical model...\")\n",
    "\n",
    "        if self.basic_model is None:\n",
    "            self.build_basic_model()\n",
    "\n",
    "        with self.basic_model:\n",
    "            # Sample from posterior\n",
    "            self.basic_trace = pm.sample(\n",
    "                draws=draws,\n",
    "                tune=tune,\n",
    "                chains=chains,\n",
    "                cores=cores,\n",
    "                random_seed=42,\n",
    "                return_inferencedata=True,\n",
    "                target_accept=0.95  # Higher target acceptance for better sampling\n",
    "            )\n",
    "\n",
    "            # Sample posterior predictive\n",
    "            with self.basic_model:\n",
    "                self.basic_trace.extend(pm.sample_posterior_predictive(self.basic_trace))\n",
    "\n",
    "        print(\"Basic model fitting completed!\")\n",
    "        return self.basic_trace\n",
    "\n",
    "    # ===== VISUALIZATION METHODS (from Model 1) =====\n",
    "\n",
    "    def get_home_advantage_summary(self, model_type='basic'):\n",
    "        \"\"\"Get summary statistics for home advantage effect\"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return None\n",
    "\n",
    "        # Extract home advantage samples\n",
    "        home_adv_samples = trace.posterior['home_advantage']\n",
    "\n",
    "        # Calculate summary statistics\n",
    "        home_summary = {\n",
    "            'parameter': 'home_advantage',\n",
    "            'mean': float(home_adv_samples.mean()),\n",
    "            'median': float(home_adv_samples.median()),\n",
    "            'std': float(home_adv_samples.std()),\n",
    "            'q025': float(home_adv_samples.quantile(0.025)),\n",
    "            'q975': float(home_adv_samples.quantile(0.975))\n",
    "        }\n",
    "\n",
    "        return home_summary\n",
    "\n",
    "    def plot_team_effects(self, model_type='basic'):\n",
    "        \"\"\"Plot attack vs defense effects for each team\"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return\n",
    "\n",
    "        # Get posterior means\n",
    "        if model_type == 'basic':\n",
    "            att_means = trace.posterior['att'].mean(dim=['chain', 'draw']).values\n",
    "            def_means = trace.posterior['def'].mean(dim=['chain', 'draw']).values\n",
    "        else:\n",
    "            att_means = trace.posterior['att_centered'].mean(dim=['chain', 'draw']).values\n",
    "            def_means = trace.posterior['def_centered'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "        # Create plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.scatter(att_means, def_means, s=100, alpha=0.7)\n",
    "\n",
    "        # Add team labels\n",
    "        for i, team in enumerate(self.teams):\n",
    "            plt.annotate(team, (att_means[i], def_means[i]),\n",
    "                        xytext=(5, 5), textcoords='offset points',\n",
    "                        fontsize=8, alpha=0.8)\n",
    "\n",
    "        plt.xlabel('Attack Effect')\n",
    "        plt.ylabel('Defense Effect')\n",
    "        plt.title(f'Team Attack vs Defense Effects ({model_type.title()} Model)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "        plt.axvline(x=0, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Add quadrant labels\n",
    "        plt.text(0.02, 0.98, 'Poor Attack,\\nPoor Defense',\n",
    "                transform=plt.gca().transAxes, va='top', ha='left',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))\n",
    "        plt.text(0.98, 0.98, 'Good Attack,\\nPoor Defense',\n",
    "                transform=plt.gca().transAxes, va='top', ha='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
    "        plt.text(0.02, 0.02, 'Poor Attack,\\nGood Defense',\n",
    "                transform=plt.gca().transAxes, va='bottom', ha='left',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "        plt.text(0.98, 0.02, 'Good Attack,\\nGood Defense',\n",
    "                transform=plt.gca().transAxes, va='bottom', ha='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    #     return summary_df\n",
    "    def get_team_summary(self, model_type='basic'):\n",
    "        \"\"\"Get summary statistics for team effects for *all* teams\"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return None\n",
    "\n",
    "        # pick parameter names\n",
    "        att_param = 'att' if model_type=='basic' else 'att_centered'\n",
    "        def_param = 'def' if model_type=='basic' else 'def_centered'\n",
    "\n",
    "        att_samples = trace.posterior[att_param]\n",
    "        def_samples = trace.posterior[def_param]\n",
    "\n",
    "        summary_data = []\n",
    "        for i, team in enumerate(self.teams):\n",
    "            # select draws for team i\n",
    "            att_i = att_samples.sel({att_samples.dims[-1]: i})\n",
    "            def_i = def_samples.sel({def_samples.dims[-1]: i})\n",
    "\n",
    "            # flatten (chain,draw) into one dimension\n",
    "            att_flat = att_i.values.reshape(-1)\n",
    "            def_flat = def_i.values.reshape(-1)\n",
    "\n",
    "            summary_data.append({\n",
    "                'team': team,\n",
    "                'att_mean':   np.mean(att_flat),\n",
    "                'att_median': np.quantile(att_flat, 0.5),\n",
    "                'att_q025':   np.quantile(att_flat, 0.025),\n",
    "                'att_q975':   np.quantile(att_flat, 0.975),\n",
    "                'def_mean':   np.mean(def_flat),\n",
    "                'def_median': np.quantile(def_flat, 0.5),\n",
    "                'def_q025':   np.quantile(def_flat, 0.025),\n",
    "                'def_q975':   np.quantile(def_flat, 0.975),\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        # sort by attack mean descending (just like Table 2)\n",
    "        return df.sort_values('att_mean', ascending=False)\n",
    "\n",
    "    # 1. Pull the two pieces from your model\n",
    "    team_df = model.get_team_summary(model_type='basic')\n",
    "    home_dict = model.get_home_advantage_summary(model_type='basic')\n",
    "\n",
    "    # Turn the homeâ€advantage dict into a 1-row DataFrame\n",
    "    home_df = pd.DataFrame([{\n",
    "        'parameter': home_dict['parameter'],\n",
    "        'mean':      home_dict['mean'],\n",
    "        'median':    home_dict['median'],\n",
    "        'q025':      home_dict['q025'],\n",
    "        'q975':      home_dict['q975']\n",
    "    }])\n",
    "\n",
    "    # 2. Write both to an .xlsx file\n",
    "    output_path = \"Table2_SerieA_2007-08.xlsx\"\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        team_df.to_excel(\n",
    "            writer,\n",
    "            sheet_name='Team Effects',\n",
    "            index=False,\n",
    "            float_format=\"%.4f\"\n",
    "        )\n",
    "        home_df.to_excel(\n",
    "            writer,\n",
    "            sheet_name='Home Advantage',\n",
    "            index=False,\n",
    "            float_format=\"%.4f\"\n",
    "        )\n",
    "\n",
    "    print(f\" Saved Table 2 to {output_path}\")\n",
    "\n",
    "    def print_model_summary(self, model_type='basic', show_all_teams=True):\n",
    "        \"\"\"Print comprehensive model summary including home advantage\"\"\"\n",
    "\n",
    "        print(f\"\\n{model_type.upper()} MODEL SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Home advantage\n",
    "        home_summary = self.get_home_advantage_summary(model_type)\n",
    "        if home_summary:\n",
    "            print(f\"\\nHOME ADVANTAGE EFFECT:\")\n",
    "            print(f\"Mean: {home_summary['mean']:.4f}\")\n",
    "            print(f\"95% CI: [{home_summary['q025']:.4f}, {home_summary['q975']:.4f}]\")\n",
    "            print(f\"Interpretation: Home teams score exp({home_summary['mean']:.4f}) = {np.exp(home_summary['mean']):.3f}x more goals on average\")\n",
    "\n",
    "        # Team effects\n",
    "        print(f\"\\nTEAM EFFECTS (all {len(self.teams)} teams):\")\n",
    "        team_summary = self.get_team_summary(model_type)\n",
    "        if team_summary is None:\n",
    "            return\n",
    "\n",
    "        # Reorder columns for readability\n",
    "        cols = [\n",
    "        'team',\n",
    "        'att_mean','att_median','att_q025','att_q975',\n",
    "        'def_mean','def_median','def_q025','def_q975'\n",
    "        ]\n",
    "        print(team_summary[cols].to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "    def predict_match(self, home_team, away_team, model_type='basic', n_samples=1000):\n",
    "        \"\"\"Predict the outcome of a specific match\"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return None\n",
    "\n",
    "        # Get team indices\n",
    "        if home_team not in self.teams or away_team not in self.teams:\n",
    "            print(f\"Team not found. Available teams: {self.teams}\")\n",
    "            return None\n",
    "\n",
    "        home_idx = self.teams.index(home_team)\n",
    "        away_idx = self.teams.index(away_team)\n",
    "\n",
    "        # Get parameter samples\n",
    "        home_adv_samples = trace.posterior['home_advantage'].values.flatten()\n",
    "\n",
    "        if model_type == 'basic':\n",
    "            att_samples = trace.posterior['att'].values\n",
    "            def_samples = trace.posterior['def'].values\n",
    "        else:\n",
    "            att_samples = trace.posterior['att_centered'].values\n",
    "            def_samples = trace.posterior['def_centered'].values\n",
    "\n",
    "        # Reshape samples for easier indexing\n",
    "        att_flat = att_samples.reshape(-1, att_samples.shape[-1])\n",
    "        def_flat = def_samples.reshape(-1, def_samples.shape[-1])\n",
    "        home_adv_flat = home_adv_samples.flatten()\n",
    "\n",
    "        # Take only n_samples\n",
    "        n_available = min(len(home_adv_flat), len(att_flat))\n",
    "        n_use = min(n_samples, n_available)\n",
    "\n",
    "        # Calculate scoring intensities\n",
    "        theta1_samples = np.exp(home_adv_flat[:n_use] +\n",
    "                               att_flat[:n_use, home_idx] +\n",
    "                               def_flat[:n_use, away_idx])\n",
    "\n",
    "        theta2_samples = np.exp(att_flat[:n_use, away_idx] +\n",
    "                               def_flat[:n_use, home_idx])\n",
    "\n",
    "        # Generate predictions\n",
    "        home_goals = np.random.poisson(theta1_samples)\n",
    "        away_goals = np.random.poisson(theta2_samples)\n",
    "\n",
    "        # Calculate probabilities\n",
    "        home_win = np.mean(home_goals > away_goals)\n",
    "        draw = np.mean(home_goals == away_goals)\n",
    "        away_win = np.mean(home_goals < away_goals)\n",
    "\n",
    "        # Expected goals\n",
    "        exp_home_goals = np.mean(theta1_samples)\n",
    "        exp_away_goals = np.mean(theta2_samples)\n",
    "\n",
    "        return {\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'expected_home_goals': exp_home_goals,\n",
    "            'expected_away_goals': exp_away_goals,\n",
    "            'prob_home_win': home_win,\n",
    "            'prob_draw': draw,\n",
    "            'prob_away_win': away_win,\n",
    "            'home_goals_samples': home_goals,\n",
    "            'away_goals_samples': away_goals\n",
    "        }\n",
    "\n",
    "    # ===== COMBINED ANALYSIS METHODS =====\n",
    "\n",
    "    def run_complete_analysis(self, draws_basic=3000, draws_mixture=1000, save_results=True):\n",
    "        \"\"\"\n",
    "        Run complete analysis with both models including visualizations and comparisons\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"=\"*70)\n",
    "        print(\"COMPLETE BAYESIAN FOOTBALL MODEL ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # Fit basic model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"FITTING BASIC MODEL\")\n",
    "        print(\"=\"*50)\n",
    "        basic_trace = self.fit_basic_model(draws=draws_basic, tune=draws_basic, chains=4)\n",
    "\n",
    "        # Basic model analysis\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"BASIC MODEL ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        self.print_model_summary('basic', show_all_teams=True)\n",
    "\n",
    "        # Plot basic model effects\n",
    "        self.plot_team_effects('basic')\n",
    "\n",
    "# ===== USAGE EXAMPLE =====\n",
    "\n",
    "def run_example_analysis(data_file):\n",
    "    \"\"\"\n",
    "    Example function showing how to use the integrated model\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the model\n",
    "    print(\"Initializing Bayesian Football Model...\")\n",
    "    model = BayesianFootballModel(data_file)\n",
    "\n",
    "    # Run complete analysis\n",
    "    results = model.run_complete_analysis(\n",
    "        draws_basic=1000,    # Adjust based on your computational resources\n",
    "        save_results=True\n",
    "    )\n",
    "\n",
    "    return model, results\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"INTEGRATED BAYESIAN FOOTBALL MODEL\")\n",
    "    print(\"Combines Visualization + Comparison Tables + Predictions\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Replace with your actual file path\n",
    "    data_file = '/content/final dataset 2007-08.xlsx'\n",
    "\n",
    "    try:\n",
    "        # Run the complete analysis\n",
    "        model, results = run_example_analysis(data_file)\n",
    "\n",
    "        print(\"\\nSUCCESS! All analysis completed.\")\n",
    "        print(\"\\nYou can now use the model object to:\")\n",
    "        print(\"- model.predict_match('Team1', 'Team2', 'basic')\")\n",
    "        print(\"- model.plot_team_effects('mixture')\")\n",
    "        print(\"- model.print_model_summary('basic')\")\n",
    "        print(\"- model.create_extended_comparison_table()\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error during analysis: {e}\")\n",
    "        print(\"Please check that your data file exists and has the correct format.\")\n",
    "        print(\"Required columns: hometeam_name, awayteam_name, y1, y2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bz9q5TjZoExa"
   },
   "source": [
    "# Final Base Code (Basic + Mixture) - Implemented on 2007/08 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2b1af520331c468695861a0d06fcdfef",
      "432b3d1ebef9416b86c6d84090a5b73c",
      "59db50a613404f90983233a2a7f93142",
      "18a5205f70f541899fd6e2a1d063e94b",
      "88bcede7fc6c4ea19824e28ea8a3ab7d",
      "efdc6f9d72ad455a94b9f4e923d79e1b",
      "cff403a458c64bce8de020d08ffc6747",
      "2c3973a318ae4ce19216cf30cf4a57eb"
     ]
    },
    "id": "tlXC-q5MoD6Y",
    "outputId": "5b2a8385-4e4a-4e8b-dfc4-4dbb7b82567b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BayesianFootballModel:\n",
    "    \"\"\"\n",
    "    Bayesian hierarchical model for football match prediction\n",
    "    Based on Baio & Blangiardo (2010) paper\n",
    "\n",
    "    Combines visualization capabilities and comparison table functionality\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_file):\n",
    "        \"\"\"Initialize the model with data\"\"\"\n",
    "        print(f\"Initializing model with data file: {data_file}\")\n",
    "\n",
    "        # Initialize model attributes first (but not data attributes)\n",
    "        self.basic_model = None\n",
    "        self.mixture_model = None\n",
    "        self.basic_trace = None\n",
    "        self.mixture_trace = None\n",
    "\n",
    "        try:\n",
    "            self.data = self.load_and_prepare_data(data_file)\n",
    "            print(\" Model initialization completed successfully\")\n",
    "            print(f\" Final check - n_games: {self.n_games}, n_teams: {self.n_teams}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error during model initialization: {e}\")\n",
    "            print(\"Please check that the data file exists and has the correct format\")\n",
    "            raise\n",
    "\n",
    "    def load_and_prepare_data(self, data_file):\n",
    "        \"\"\"Load and prepare the football data\"\"\"\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel('/data/dataset/dataset_2007-08.xlsx')\n",
    "\n",
    "        # Clean column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "        # Create team mappings - using correct column names\n",
    "        all_teams = pd.concat([\n",
    "            df['hometeam_name'],\n",
    "            df['awayteam_name']\n",
    "        ]).unique()\n",
    "\n",
    "        team_to_id = {team: i for i, team in enumerate(sorted(all_teams))}\n",
    "        id_to_team = {i: team for team, i in team_to_id.items()}\n",
    "\n",
    "        # Map team names to consecutive IDs (0-based)\n",
    "        df['home_team_idx'] = df['hometeam_name'].map(team_to_id)\n",
    "        df['away_team_idx'] = df['awayteam_name'].map(team_to_id)\n",
    "\n",
    "        # Check for any mapping issues\n",
    "        if df['home_team_idx'].isna().any() or df['away_team_idx'].isna().any():\n",
    "            print(\"Warning: Some teams could not be mapped!\")\n",
    "            print(\"Home team mapping issues:\", df[df['home_team_idx'].isna()]['hometeam_name'].unique())\n",
    "            print(\"Away team mapping issues:\", df[df['away_team_idx'].isna()]['awayteam_name'].unique())\n",
    "\n",
    "        # Store team information\n",
    "        self.teams = sorted(all_teams)\n",
    "        self.n_teams = len(self.teams)\n",
    "        self.n_games = len(df)\n",
    "\n",
    "        print(f\"Data loaded: {self.n_games} games, {self.n_teams} teams\")\n",
    "        print(f\"Teams: {self.teams}\")\n",
    "\n",
    "        # Verify no None values\n",
    "        print(f\"n_games type: {type(self.n_games)}, value: {self.n_games}\")\n",
    "        print(f\"n_teams type: {type(self.n_teams)}, value: {self.n_teams}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def build_basic_model(self):\n",
    "        \"\"\"Build the basic hierarchical model from Section 2 of the paper\"\"\"\n",
    "\n",
    "        # Check if data is properly loaded\n",
    "        if self.n_games is None or self.n_teams is None:\n",
    "            raise ValueError(\"Data not properly loaded. Please check the data file and team mappings.\")\n",
    "\n",
    "        print(f\"Building model with {self.n_games} games and {self.n_teams} teams\")\n",
    "\n",
    "        # Prepare data arrays\n",
    "        home_team_idx = self.data['home_team_idx'].values\n",
    "        away_team_idx = self.data['away_team_idx'].values\n",
    "        y1_data = self.data['y1'].values\n",
    "        y2_data = self.data['y2'].values\n",
    "\n",
    "        # Verify data integrity\n",
    "        print(f\"Home team indices range: {home_team_idx.min()} to {home_team_idx.max()}\")\n",
    "        print(f\"Away team indices range: {away_team_idx.min()} to {away_team_idx.max()}\")\n",
    "        print(f\"Goals range - Home: {y1_data.min()} to {y1_data.max()}, Away: {y2_data.min()} to {y2_data.max()}\")\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            # Home advantage parameter\n",
    "            home_advantage = pm.Normal(\"home_advantage\", mu=0, tau=0.0001)\n",
    "\n",
    "            # Hyperparameters for attack and defense effects\n",
    "            mu_att = pm.Normal(\"mu_att\", mu=0, tau=0.0001)\n",
    "            mu_def = pm.Normal(\"mu_def\", mu=0, tau=0.0001)\n",
    "            tau_att = pm.Gamma(\"tau_att\", alpha=0.01, beta=0.01)\n",
    "            tau_def = pm.Gamma(\"tau_def\", alpha=0.01, beta=0.01)\n",
    "\n",
    "            # Team-specific attack and defense effects (before centering)\n",
    "            att_star = pm.Normal(\"att_star\", mu=mu_att, tau=tau_att, shape=self.n_teams)\n",
    "            def_star = pm.Normal(\"def_star\", mu=mu_def, tau=tau_def, shape=self.n_teams)\n",
    "\n",
    "            # Sum-to-zero constraint (centering)\n",
    "            att = pm.Deterministic(\"att\", att_star - pt.mean(att_star))\n",
    "            def_ = pm.Deterministic(\"def\", def_star - pt.mean(def_star))\n",
    "\n",
    "            # CORRECTED: Direct indexing for game-specific theta values\n",
    "            # For each game g:\n",
    "            # log(theta_g1) = home + att[h(g)] + def[a(g)]  (home team scoring intensity)\n",
    "            # log(theta_g2) = att[a(g)] + def[h(g)]        (away team scoring intensity)\n",
    "\n",
    "            log_theta_g1 = home_advantage + att[home_team_idx] + def_[away_team_idx]\n",
    "            log_theta_g2 = att[away_team_idx] + def_[home_team_idx]\n",
    "\n",
    "            theta_g1 = pm.Deterministic(\"theta_g1\", pt.exp(log_theta_g1))\n",
    "            theta_g2 = pm.Deterministic(\"theta_g2\", pt.exp(log_theta_g2))\n",
    "\n",
    "            # Likelihood - each game has its own theta values\n",
    "            y1 = pm.Poisson(\"y1\", mu=theta_g1, observed=y1_data)\n",
    "            y2 = pm.Poisson(\"y2\", mu=theta_g2, observed=y2_data)\n",
    "\n",
    "        print(\"Model built successfully!\")\n",
    "        self.basic_model = model\n",
    "        return model\n",
    "\n",
    "    def build_mixture_model(self):\n",
    "        \"\"\"Build the mixture model from Section 4 of the paper\"\"\"\n",
    "\n",
    "        # Prepare data arrays\n",
    "        home_team_idx = self.data['home_team_idx'].values\n",
    "        away_team_idx = self.data['away_team_idx'].values\n",
    "        y1_data = self.data['y1'].values\n",
    "        y2_data = self.data['y2'].values\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            # Home advantage parameter\n",
    "            home_advantage = pm.Normal(\"home_advantage\", mu=0, tau=0.0001)\n",
    "\n",
    "            # Mixture parameters for each team\n",
    "            # Prior probabilities for group membership (3 groups: bottom, mid, top)\n",
    "            alpha_att = np.ones(3)  # Uniform prior over groups\n",
    "            alpha_def = np.ones(3)\n",
    "\n",
    "            p_att = pm.Dirichlet(\"p_att\", a=alpha_att, shape=(self.n_teams, 3))\n",
    "            p_def = pm.Dirichlet(\"p_def\", a=alpha_def, shape=(self.n_teams, 3))\n",
    "\n",
    "            # Group assignment for each team\n",
    "            grp_att = pm.Categorical(\"grp_att\", p=p_att, shape=self.n_teams)\n",
    "            grp_def = pm.Categorical(\"grp_def\", p=p_def, shape=self.n_teams)\n",
    "\n",
    "            # Group-specific parameters\n",
    "            # Group 1: Bottom teams (poor attack, poor defense)\n",
    "            mu_att_1 = pm.TruncatedNormal(\"mu_att_1\", mu=0, tau=0.001, lower=-3, upper=0)\n",
    "            mu_def_1 = pm.TruncatedNormal(\"mu_def_1\", mu=0, tau=0.001, lower=0, upper=3)\n",
    "            tau_att_1 = pm.Gamma(\"tau_att_1\", alpha=0.01, beta=0.01)\n",
    "            tau_def_1 = pm.Gamma(\"tau_def_1\", alpha=0.01, beta=0.01)\n",
    "\n",
    "            # Group 2: Mid-table teams (average)\n",
    "            tau_att_2 = pm.Gamma(\"tau_att_2\", alpha=0.01, beta=0.01)\n",
    "            tau_def_2 = pm.Gamma(\"tau_def_2\", alpha=0.01, beta=0.01)\n",
    "            mu_att_2 = pm.Normal(\"mu_att_2\", mu=0, tau=tau_att_2)\n",
    "            mu_def_2 = pm.Normal(\"mu_def_2\", mu=0, tau=tau_def_2)\n",
    "\n",
    "            # Group 3: Top teams (good attack, good defense)\n",
    "            mu_att_3 = pm.TruncatedNormal(\"mu_att_3\", mu=0, tau=0.001, lower=0, upper=3)\n",
    "            mu_def_3 = pm.TruncatedNormal(\"mu_def_3\", mu=0, tau=0.001, lower=-3, upper=0)\n",
    "            tau_att_3 = pm.Gamma(\"tau_att_3\", alpha=0.01, beta=0.01)\n",
    "            tau_def_3 = pm.Gamma(\"tau_def_3\", alpha=0.01, beta=0.01)\n",
    "\n",
    "            # Stack parameters\n",
    "            mu_att_groups = pt.stack([mu_att_1, mu_att_2, mu_att_3])\n",
    "            mu_def_groups = pt.stack([mu_def_1, mu_def_2, mu_def_3])\n",
    "            tau_att_groups = pt.stack([tau_att_1, tau_att_2, tau_att_3])\n",
    "            tau_def_groups = pt.stack([tau_def_1, tau_def_2, tau_def_3])\n",
    "\n",
    "            # Team-specific effects using t-distribution with 4 degrees of freedom (as in paper)\n",
    "            att_effects = []\n",
    "            def_effects = []\n",
    "\n",
    "            for t in range(self.n_teams):\n",
    "                # For each team, determine which group they belong to and use appropriate parameters\n",
    "                att_mu_t = pt.switch(pt.eq(grp_att[t], 0), mu_att_groups[0],\n",
    "                                   pt.switch(pt.eq(grp_att[t], 1), mu_att_groups[1], mu_att_groups[2]))\n",
    "                att_tau_t = pt.switch(pt.eq(grp_att[t], 0), tau_att_groups[0],\n",
    "                                    pt.switch(pt.eq(grp_att[t], 1), tau_att_groups[1], tau_att_groups[2]))\n",
    "\n",
    "                def_mu_t = pt.switch(pt.eq(grp_def[t], 0), mu_def_groups[0],\n",
    "                                   pt.switch(pt.eq(grp_def[t], 1), mu_def_groups[1], mu_def_groups[2]))\n",
    "                def_tau_t = pt.switch(pt.eq(grp_def[t], 0), tau_def_groups[0],\n",
    "                                    pt.switch(pt.eq(grp_def[t], 1), tau_def_groups[1], tau_def_groups[2]))\n",
    "\n",
    "                # Use StudentT with nu=4 degrees of freedom as in the paper\n",
    "                att_t = pm.StudentT(f\"att_raw_{t}\", nu=4, mu=att_mu_t, lam=att_tau_t)\n",
    "                def_t = pm.StudentT(f\"def_raw_{t}\", nu=4, mu=def_mu_t, lam=def_tau_t)\n",
    "\n",
    "                att_effects.append(att_t)\n",
    "                def_effects.append(def_t)\n",
    "\n",
    "            att = pt.stack(att_effects)\n",
    "            def_ = pt.stack(def_effects)\n",
    "\n",
    "            # Apply sum-to-zero constraint\n",
    "            att_centered = pm.Deterministic(\"att_centered\", att - pt.mean(att))\n",
    "            def_centered = pm.Deterministic(\"def_centered\", def_ - pt.mean(def_))\n",
    "\n",
    "            # CORRECTED: Direct indexing for game-specific theta values (same as basic model)\n",
    "            # For each game g:\n",
    "            # log(theta_g1) = home + att[h(g)] + def[a(g)]  (home team scoring intensity)\n",
    "            # log(theta_g2) = att[a(g)] + def[h(g)]        (away team scoring intensity)\n",
    "\n",
    "            log_theta_g1 = home_advantage + att_centered[home_team_idx] + def_centered[away_team_idx]\n",
    "            log_theta_g2 = att_centered[away_team_idx] + def_centered[home_team_idx]\n",
    "\n",
    "            theta_g1 = pm.Deterministic(\"theta_g1\", pt.exp(log_theta_g1))\n",
    "            theta_g2 = pm.Deterministic(\"theta_g2\", pt.exp(log_theta_g2))\n",
    "\n",
    "            # Likelihood - each game has its own theta values\n",
    "            y1 = pm.Poisson(\"y1\", mu=theta_g1, observed=y1_data)\n",
    "            y2 = pm.Poisson(\"y2\", mu=theta_g2, observed=y2_data)\n",
    "\n",
    "        self.mixture_model = model\n",
    "        return model\n",
    "\n",
    "    def fit_basic_model(self, draws=2000, tune=2000, chains=4, cores=1):\n",
    "        \"\"\"Fit the basic hierarchical model\"\"\"\n",
    "        print(\"Fitting basic hierarchical model...\")\n",
    "\n",
    "        if self.basic_model is None:\n",
    "            self.build_basic_model()\n",
    "\n",
    "        with self.basic_model:\n",
    "            # Sample from posterior\n",
    "            self.basic_trace = pm.sample(\n",
    "                draws=draws,\n",
    "                tune=tune,\n",
    "                chains=chains,\n",
    "                cores=cores,\n",
    "                random_seed=42,\n",
    "                return_inferencedata=True,\n",
    "                target_accept=0.97  # Higher target acceptance for better sampling\n",
    "            )\n",
    "\n",
    "            # Sample posterior predictive\n",
    "            with self.basic_model:\n",
    "                self.basic_trace.extend(pm.sample_posterior_predictive(self.basic_trace))\n",
    "\n",
    "        print(\"Basic model fitting completed!\")\n",
    "        return self.basic_trace\n",
    "\n",
    "    def fit_mixture_model(self, draws=2000, tune=2000, chains=4, cores=1):\n",
    "        \"\"\"Fit the mixture model\"\"\"\n",
    "        print(\"Fitting mixture model...\")\n",
    "\n",
    "        if self.mixture_model is None:\n",
    "            self.build_mixture_model()\n",
    "\n",
    "        with self.mixture_model:\n",
    "            # Sample from posterior with simplified parameters\n",
    "            self.mixture_trace = pm.sample(\n",
    "                draws=draws,\n",
    "                tune=tune,\n",
    "                chains=chains,\n",
    "                cores=cores,\n",
    "                random_seed=42,\n",
    "                return_inferencedata=True,\n",
    "                target_accept=0.97  # Slightly lower target acceptance to avoid issues\n",
    "            )\n",
    "\n",
    "            # Sample posterior predictive\n",
    "            with self.mixture_model:\n",
    "                self.mixture_trace.extend(pm.sample_posterior_predictive(self.mixture_trace))\n",
    "\n",
    "        print(\"Mixture model fitting completed!\")\n",
    "        return self.mixture_trace\n",
    "\n",
    "    # ===== REALISTIC SIMULATION METHODS =====\n",
    "\n",
    "    def get_realistic_model_predictions(self, model_type, n_simulations=1500):\n",
    "        \"\"\"\n",
    "        Get realistic predictions by simulating actual match outcomes\n",
    "        Using MEDIAN of season totals (exactly like the paper)\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Warning: {model_type} model not fitted, skipping...\")\n",
    "            return None\n",
    "\n",
    "        # Get posterior samples of scoring intensities (theta values)\n",
    "        if 'theta_g1' in trace.posterior.data_vars and 'theta_g2' in trace.posterior.data_vars:\n",
    "            theta1_samples = trace.posterior['theta_g1'].values  # [chains, draws, games]\n",
    "            theta2_samples = trace.posterior['theta_g2'].values  # [chains, draws, games]\n",
    "        else:\n",
    "            print(f\"Could not find theta variables in {model_type} model\")\n",
    "            print(\"Available variables:\", list(trace.posterior.data_vars))\n",
    "            return None\n",
    "\n",
    "        # Reshape for easier handling\n",
    "        n_chains, n_draws, n_games = theta1_samples.shape\n",
    "        theta1_flat = theta1_samples.reshape(-1, n_games)  # [total_samples, games]\n",
    "        theta2_flat = theta2_samples.reshape(-1, n_games)\n",
    "\n",
    "        n_available_samples = len(theta1_flat)\n",
    "\n",
    "        # If we have fewer samples than desired, resample with replacement\n",
    "        if n_available_samples < n_simulations:\n",
    "            print(f\"Only {n_available_samples} posterior samples available, resampling to get {n_simulations}...\")\n",
    "            resample_indices = np.random.choice(n_available_samples, size=n_simulations, replace=True)\n",
    "            theta1_sim = theta1_flat[resample_indices]\n",
    "            theta2_sim = theta2_flat[resample_indices]\n",
    "            n_samples = n_simulations\n",
    "        else:\n",
    "            theta1_sim = theta1_flat[:n_simulations]\n",
    "            theta2_sim = theta2_flat[:n_simulations]\n",
    "            n_samples = n_simulations\n",
    "\n",
    "        print(f\"Simulating {n_samples} scenarios for {model_type} model predictions...\")\n",
    "\n",
    "        pred_stats = []\n",
    "\n",
    "        for team in self.teams:\n",
    "            # Get indices for this team's games\n",
    "            team_home_mask = (self.data['hometeam_name'] == team)\n",
    "            team_away_mask = (self.data['awayteam_name'] == team)\n",
    "            team_mask = team_home_mask | team_away_mask\n",
    "\n",
    "            team_games = self.data[team_mask].copy()\n",
    "\n",
    "            # Store season totals for each simulation\n",
    "            season_points = []\n",
    "            season_goals_scored = []\n",
    "            season_goals_conceded = []\n",
    "            season_wins = []\n",
    "            season_draws = []\n",
    "            season_losses = []\n",
    "\n",
    "            # For each posterior sample, simulate a complete season\n",
    "            for sim_idx in range(n_samples):\n",
    "                sim_points = 0\n",
    "                sim_goals_scored = 0\n",
    "                sim_goals_conceded = 0\n",
    "                sim_wins = 0\n",
    "                sim_draws = 0\n",
    "                sim_losses = 0\n",
    "\n",
    "                # Simulate all matches for this team in this posterior sample\n",
    "                for _, match in team_games.iterrows():\n",
    "                    game_idx = match.name  # original index in dataset\n",
    "\n",
    "                    # Get theta values for this specific simulation\n",
    "                    game_theta1 = theta1_sim[sim_idx, game_idx]  # home team scoring intensity\n",
    "                    game_theta2 = theta2_sim[sim_idx, game_idx]  # away team scoring intensity\n",
    "\n",
    "                    # Simulate actual goals for this specific match\n",
    "                    simulated_home_goals = np.random.poisson(game_theta1)\n",
    "                    simulated_away_goals = np.random.poisson(game_theta2)\n",
    "\n",
    "                    # Determine team's perspective\n",
    "                    if match['hometeam_name'] == team:\n",
    "                        # Team is playing at home\n",
    "                        team_goals = simulated_home_goals\n",
    "                        opponent_goals = simulated_away_goals\n",
    "                    else:\n",
    "                        # Team is playing away\n",
    "                        team_goals = simulated_away_goals\n",
    "                        opponent_goals = simulated_home_goals\n",
    "\n",
    "                    # Update season totals for this simulation\n",
    "                    sim_goals_scored += team_goals\n",
    "                    sim_goals_conceded += opponent_goals\n",
    "\n",
    "                    # Determine match result\n",
    "                    if team_goals > opponent_goals:\n",
    "                        sim_points += 3\n",
    "                        sim_wins += 1\n",
    "                    elif team_goals == opponent_goals:\n",
    "                        sim_points += 1\n",
    "                        sim_draws += 1\n",
    "                    else:\n",
    "                        sim_losses += 1\n",
    "\n",
    "                # Store this simulation's season totals\n",
    "                season_points.append(sim_points)\n",
    "                season_goals_scored.append(sim_goals_scored)\n",
    "                season_goals_conceded.append(sim_goals_conceded)\n",
    "                season_wins.append(sim_wins)\n",
    "                season_draws.append(sim_draws)\n",
    "                season_losses.append(sim_losses)\n",
    "\n",
    "            # Take MEDIAN of season totals (exactly like the paper)\n",
    "            pred_stats.append({\n",
    "                'team': team,\n",
    "                f'{model_type}_points': int(np.median(season_points)),\n",
    "                f'{model_type}_scored': int(np.median(season_goals_scored)),\n",
    "                f'{model_type}_conceded': int(np.median(season_goals_conceded)),\n",
    "                f'{model_type}_wins': int(np.median(season_wins)),\n",
    "                f'{model_type}_draws': int(np.median(season_draws)),\n",
    "                f'{model_type}_losses': int(np.median(season_losses))\n",
    "            })\n",
    "\n",
    "        return pred_stats\n",
    "\n",
    "    def create_extended_comparison_table(self, save_to_file=False, filename=\"extended_season_comparison.csv\"):\n",
    "        \"\"\"\n",
    "        Create a comprehensive comparison table including mixture model results\n",
    "        Now includes wins, draws, and losses with REALISTIC simulation\n",
    "        \"\"\"\n",
    "\n",
    "        if self.basic_trace is None:\n",
    "            print(\"Please fit the basic model first!\")\n",
    "            return None\n",
    "\n",
    "        # Calculate observed statistics for each team\n",
    "        observed_stats = []\n",
    "\n",
    "        for team in self.teams:\n",
    "            team_data = self.data[\n",
    "                (self.data['hometeam_name'] == team) |\n",
    "                (self.data['awayteam_name'] == team)\n",
    "            ].copy()\n",
    "\n",
    "            # Calculate points, goals scored, goals conceded, wins, draws, losses\n",
    "            points = 0\n",
    "            goals_scored = 0\n",
    "            goals_conceded = 0\n",
    "            wins = 0\n",
    "            draws = 0\n",
    "            losses = 0\n",
    "\n",
    "            for _, match in team_data.iterrows():\n",
    "                if match['hometeam_name'] == team:\n",
    "                    # Team playing at home\n",
    "                    goals_for = match['y1']\n",
    "                    goals_against = match['y2']\n",
    "                else:\n",
    "                    # Team playing away\n",
    "                    goals_for = match['y2']\n",
    "                    goals_against = match['y1']\n",
    "\n",
    "                # Calculate match result\n",
    "                if goals_for > goals_against:\n",
    "                    points += 3\n",
    "                    wins += 1\n",
    "                elif goals_for == goals_against:\n",
    "                    points += 1\n",
    "                    draws += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "\n",
    "                goals_scored += goals_for\n",
    "                goals_conceded += goals_against\n",
    "\n",
    "            observed_stats.append({\n",
    "                'team': team,\n",
    "                'obs_points': points,\n",
    "                'obs_scored': goals_scored,\n",
    "                'obs_conceded': goals_conceded,\n",
    "                'obs_wins': wins,\n",
    "                'obs_draws': draws,\n",
    "                'obs_losses': losses\n",
    "            })\n",
    "\n",
    "        # Get REALISTIC predictions from both models using simulation\n",
    "        basic_predictions = self.get_realistic_model_predictions('basic')\n",
    "        mixture_predictions = self.get_realistic_model_predictions('mixture') if self.mixture_trace else None\n",
    "\n",
    "        # Combine all data\n",
    "        comparison_data = []\n",
    "        for i, obs in enumerate(observed_stats):\n",
    "            row = obs.copy()\n",
    "\n",
    "            # Add basic model predictions\n",
    "            if basic_predictions:\n",
    "                row.update(basic_predictions[i])\n",
    "\n",
    "            # Add mixture model predictions if available\n",
    "            if mixture_predictions:\n",
    "                row.update(mixture_predictions[i])\n",
    "\n",
    "            comparison_data.append(row)\n",
    "\n",
    "        # Create DataFrame and sort by observed points\n",
    "        df = pd.DataFrame(comparison_data)\n",
    "        df = df.sort_values('obs_points', ascending=False)\n",
    "\n",
    "        # Save to file if requested\n",
    "        if save_to_file:\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"Extended comparison table saved to {filename}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    # ===== VISUALIZATION METHODS =====\n",
    "\n",
    "    def get_home_advantage_summary(self, model_type='basic'):\n",
    "        \"\"\"Get summary statistics for home advantage effect\"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return None\n",
    "\n",
    "        # Extract home advantage samples\n",
    "        home_adv_samples = trace.posterior['home_advantage']\n",
    "\n",
    "        # Calculate summary statistics\n",
    "        home_summary = {\n",
    "            'parameter': 'home_advantage',\n",
    "            'mean': float(home_adv_samples.mean()),\n",
    "            'median': float(home_adv_samples.median()),\n",
    "            'std': float(home_adv_samples.std()),\n",
    "            'q025': float(home_adv_samples.quantile(0.025)),\n",
    "            'q975': float(home_adv_samples.quantile(0.975))\n",
    "        }\n",
    "\n",
    "        return home_summary\n",
    "\n",
    "    def plot_team_effects(self, model_type='basic'):\n",
    "        \"\"\"Plot attack vs defense effects for each team\"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return\n",
    "\n",
    "        # Get posterior means\n",
    "        if model_type == 'basic':\n",
    "            att_means = trace.posterior['att'].mean(dim=['chain', 'draw']).values\n",
    "            def_means = trace.posterior['def'].mean(dim=['chain', 'draw']).values\n",
    "        else:\n",
    "            att_means = trace.posterior['att_centered'].mean(dim=['chain', 'draw']).values\n",
    "            def_means = trace.posterior['def_centered'].mean(dim=['chain', 'draw']).values\n",
    "\n",
    "        # Create plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.scatter(att_means, def_means, s=100, alpha=0.7)\n",
    "\n",
    "        # Add team labels\n",
    "        for i, team in enumerate(self.teams):\n",
    "            plt.annotate(team, (att_means[i], def_means[i]),\n",
    "                        xytext=(5, 5), textcoords='offset points',\n",
    "                        fontsize=8, alpha=0.8)\n",
    "\n",
    "        plt.xlabel('Attack Effect')\n",
    "        plt.ylabel('Defense Effect')\n",
    "        plt.title(f'Team Attack vs Defense Effects ({model_type.title()} Model)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "        plt.axvline(x=0, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Add quadrant labels\n",
    "        plt.text(0.02, 0.98, 'Poor Attack,\\nPoor Defense',\n",
    "                transform=plt.gca().transAxes, va='top', ha='left',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))\n",
    "        plt.text(0.98, 0.98, 'Good Attack,\\nPoor Defense',\n",
    "                transform=plt.gca().transAxes, va='top', ha='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
    "        plt.text(0.02, 0.02, 'Poor Attack,\\nGood Defense',\n",
    "                transform=plt.gca().transAxes, va='bottom', ha='left',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "        plt.text(0.98, 0.02, 'Good Attack,\\nGood Defense',\n",
    "                transform=plt.gca().transAxes, va='bottom', ha='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_team_summary(self, model_type='basic'):\n",
    "        \"\"\"Get summary statistics for team effects\"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return None\n",
    "\n",
    "        # Get parameter names\n",
    "        if model_type == 'basic':\n",
    "            att_param = 'att'\n",
    "            def_param = 'def'\n",
    "        else:\n",
    "            att_param = 'att_centered'\n",
    "            def_param = 'def_centered'\n",
    "\n",
    "        # Extract posterior samples\n",
    "        att_samples = trace.posterior[att_param]\n",
    "        def_samples = trace.posterior[def_param]\n",
    "\n",
    "        # Calculate summary statistics\n",
    "        summary_data = []\n",
    "        for i, team in enumerate(self.teams):\n",
    "            # Handle different indexing based on parameter dimensions\n",
    "            if len(att_samples.dims) == 3:  # chain, draw, team\n",
    "                att_team_samples = att_samples.isel({list(att_samples.dims)[2]: i})\n",
    "                def_team_samples = def_samples.isel({list(def_samples.dims)[2]: i})\n",
    "            else:  # Different structure\n",
    "                att_team_samples = att_samples[..., i]\n",
    "                def_team_samples = def_samples[..., i]\n",
    "\n",
    "            att_mean = float(att_team_samples.mean())\n",
    "            att_q025 = float(att_team_samples.quantile(0.025))\n",
    "            att_q975 = float(att_team_samples.quantile(0.975))\n",
    "\n",
    "            def_mean = float(def_team_samples.mean())\n",
    "            def_q025 = float(def_team_samples.quantile(0.025))\n",
    "            def_q975 = float(def_team_samples.quantile(0.975))\n",
    "\n",
    "            summary_data.append({\n",
    "                'team': team,\n",
    "                'att_mean': att_mean,\n",
    "                'att_q025': att_q025,\n",
    "                'att_q975': att_q975,\n",
    "                'def_mean': def_mean,\n",
    "                'def_q025': def_q025,\n",
    "                'def_q975': def_q975\n",
    "            })\n",
    "\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "        # Sort by attack effect (descending)\n",
    "        summary_df = summary_df.sort_values('att_mean', ascending=False)\n",
    "\n",
    "        return summary_df\n",
    "\n",
    "    def print_model_summary(self, model_type='basic', show_all_teams=True):\n",
    "        \"\"\"Print comprehensive model summary including home advantage\"\"\"\n",
    "\n",
    "        print(f\"\\n{model_type.upper()} MODEL SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Home advantage\n",
    "        home_summary = self.get_home_advantage_summary(model_type)\n",
    "        if home_summary:\n",
    "            print(f\"\\nHOME ADVANTAGE EFFECT:\")\n",
    "            print(f\"Mean: {home_summary['mean']:.4f}\")\n",
    "            print(f\"95% CI: [{home_summary['q025']:.4f}, {home_summary['q975']:.4f}]\")\n",
    "            print(f\"Interpretation: Home teams score exp({home_summary['mean']:.4f}) = {np.exp(home_summary['mean']):.3f}x more goals on average\")\n",
    "\n",
    "        # Team effects\n",
    "        print(f\"\\nTEAM EFFECTS:\")\n",
    "        team_summary = self.get_team_summary(model_type)\n",
    "        if team_summary is not None:\n",
    "            print(\"\\nTop 5 Attack (most goals scored):\")\n",
    "            print(team_summary.head()[['team', 'att_mean', 'att_q025', 'att_q975']].to_string(index=False))\n",
    "\n",
    "            print(f\"\\nTop 5 Defense (fewest goals conceded - most negative values):\")\n",
    "            defense_sorted = team_summary.sort_values('def_mean', ascending=True)\n",
    "            print(defense_sorted.head()[['team', 'def_mean', 'def_q025', 'def_q975']].to_string(index=False))\n",
    "\n",
    "            if show_all_teams:\n",
    "                print(f\"\\nBottom 5 Attack (fewest goals scored):\")\n",
    "                attack_sorted = team_summary.sort_values('att_mean', ascending=True)\n",
    "                print(attack_sorted.head()[['team', 'att_mean', 'att_q025', 'att_q975']].to_string(index=False))\n",
    "\n",
    "                print(f\"\\nBottom 5 Defense (most goals conceded - most positive values):\")\n",
    "                print(defense_sorted.tail()[['team', 'def_mean', 'def_q025', 'def_q975']].to_string(index=False))\n",
    "\n",
    "    def predict_match(self, home_team, away_team, model_type='basic', n_samples=1000):\n",
    "        \"\"\"Predict the outcome of a specific match\"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return None\n",
    "\n",
    "        # Get team indices\n",
    "        if home_team not in self.teams or away_team not in self.teams:\n",
    "            print(f\"Team not found. Available teams: {self.teams}\")\n",
    "            return None\n",
    "\n",
    "        home_idx = self.teams.index(home_team)\n",
    "        away_idx = self.teams.index(away_team)\n",
    "\n",
    "        # Get parameter samples\n",
    "        home_adv_samples = trace.posterior['home_advantage'].values.flatten()\n",
    "\n",
    "        if model_type == 'basic':\n",
    "            att_samples = trace.posterior['att'].values\n",
    "            def_samples = trace.posterior['def'].values\n",
    "        else:\n",
    "            att_samples = trace.posterior['att_centered'].values\n",
    "            def_samples = trace.posterior['def_centered'].values\n",
    "\n",
    "        # Reshape samples for easier indexing\n",
    "        att_flat = att_samples.reshape(-1, att_samples.shape[-1])\n",
    "        def_flat = def_samples.reshape(-1, def_samples.shape[-1])\n",
    "        home_adv_flat = home_adv_samples.flatten()\n",
    "\n",
    "        # Take only n_samples\n",
    "        n_available = min(len(home_adv_flat), len(att_flat))\n",
    "        n_use = min(n_samples, n_available)\n",
    "\n",
    "        # Calculate scoring intensities\n",
    "        theta1_samples = np.exp(home_adv_flat[:n_use] +\n",
    "                               att_flat[:n_use, home_idx] +\n",
    "                               def_flat[:n_use, away_idx])\n",
    "\n",
    "        theta2_samples = np.exp(att_flat[:n_use, away_idx] +\n",
    "                               def_flat[:n_use, home_idx])\n",
    "\n",
    "        # Generate predictions\n",
    "        home_goals = np.random.poisson(theta1_samples)\n",
    "        away_goals = np.random.poisson(theta2_samples)\n",
    "\n",
    "        # Calculate probabilities\n",
    "        home_win = np.mean(home_goals > away_goals)\n",
    "        draw = np.mean(home_goals == away_goals)\n",
    "        away_win = np.mean(home_goals < away_goals)\n",
    "\n",
    "        # Expected goals\n",
    "        exp_home_goals = np.mean(theta1_samples)\n",
    "        exp_away_goals = np.mean(theta2_samples)\n",
    "\n",
    "        return {\n",
    "            'home_team': home_team,\n",
    "            'away_team': away_team,\n",
    "            'expected_home_goals': exp_home_goals,\n",
    "            'expected_away_goals': exp_away_goals,\n",
    "            'prob_home_win': home_win,\n",
    "            'prob_draw': draw,\n",
    "            'prob_away_win': away_win,\n",
    "            'home_goals_samples': home_goals,\n",
    "            'away_goals_samples': away_goals\n",
    "        }\n",
    "\n",
    "    # ===== TRACEPLOTS METHODS =====\n",
    "\n",
    "    def plot_traceplots(self, model_type='basic', var_names=None, figsize=(15, 12)):\n",
    "        \"\"\"\n",
    "        Generate trace plots for MCMC diagnostics\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_type : str\n",
    "            'basic' or 'mixture' to specify which model to plot\n",
    "        var_names : list, optional\n",
    "            List of variable names to plot. If None, plots key parameters\n",
    "        figsize : tuple\n",
    "            Figure size for the plots\n",
    "        \"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nGenerating trace plots for {model_type} model...\")\n",
    "\n",
    "        # Default variables to plot if not specified\n",
    "        if var_names is None:\n",
    "            if model_type == 'basic':\n",
    "                var_names = ['home_advantage', 'mu_att', 'mu_def', 'tau_att', 'tau_def']\n",
    "                # Add a few team-specific effects for illustration\n",
    "                var_names.extend(['att', 'def'])\n",
    "            else:\n",
    "                var_names = ['home_advantage', 'mu_att_1', 'mu_att_2', 'mu_att_3',\n",
    "                           'mu_def_1', 'mu_def_2', 'mu_def_3']\n",
    "\n",
    "        # Filter variables that actually exist in the trace\n",
    "        available_vars = list(trace.posterior.data_vars)\n",
    "        var_names = [var for var in var_names if var in available_vars]\n",
    "\n",
    "        if not var_names:\n",
    "            print(f\"No specified variables found in {model_type} model trace.\")\n",
    "            print(f\"Available variables: {available_vars}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Create trace plots using ArviZ\n",
    "            ax = az.plot_trace(\n",
    "                trace,\n",
    "                var_names=var_names,\n",
    "                figsize=figsize,\n",
    "                combined=False,\n",
    "                compact=False\n",
    "            )\n",
    "\n",
    "            plt.suptitle(f'Trace Plots - {model_type.title()} Model', fontsize=16, y=0.98)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Print convergence diagnostics\n",
    "            self.print_convergence_diagnostics(model_type, var_names)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating trace plots: {e}\")\n",
    "            print(\"Trying with simpler variable selection...\")\n",
    "\n",
    "            # Fallback: just plot home_advantage if it exists\n",
    "            if 'home_advantage' in available_vars:\n",
    "                az.plot_trace(trace, var_names=['home_advantage'], figsize=(12, 4))\n",
    "                plt.suptitle(f'Trace Plot: Home Advantage - {model_type.title()} Model')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "    def print_convergence_diagnostics(self, model_type='basic', var_names=None):\n",
    "        \"\"\"\n",
    "        Print convergence diagnostics for the specified model\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_type : str\n",
    "            'basic' or 'mixture' to specify which model to diagnose\n",
    "        var_names : list, optional\n",
    "            List of variable names to diagnose. If None, uses all variables\n",
    "        \"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"CONVERGENCE DIAGNOSTICS - {model_type.upper()} MODEL\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        try:\n",
    "            # Calculate R-hat (should be < 1.1 for good convergence)\n",
    "            rhat = az.rhat(trace, var_names=var_names)\n",
    "\n",
    "            # Calculate effective sample size (should be > 400)\n",
    "            ess = az.ess(trace, var_names=var_names)\n",
    "\n",
    "            # Handle different return types from ArviZ\n",
    "            if hasattr(rhat, 'values'):\n",
    "                # If it's an xarray Dataset/DataArray, get the values\n",
    "                rhat_values = rhat.values if hasattr(rhat.values, 'flatten') else [rhat.values]\n",
    "                if hasattr(rhat_values, 'flatten'):\n",
    "                    rhat_flat = rhat_values.flatten()\n",
    "                else:\n",
    "                    rhat_flat = np.array(rhat_values).flatten()\n",
    "                max_rhat = float(np.nanmax(rhat_flat))\n",
    "            else:\n",
    "                # If it's already a scalar or array\n",
    "                max_rhat = float(np.nanmax(rhat))\n",
    "\n",
    "            if hasattr(ess, 'values'):\n",
    "                # If it's an xarray Dataset/DataArray, get the values\n",
    "                ess_values = ess.values if hasattr(ess.values, 'flatten') else [ess.values]\n",
    "                if hasattr(ess_values, 'flatten'):\n",
    "                    ess_flat = ess_values.flatten()\n",
    "                else:\n",
    "                    ess_flat = np.array(ess_values).flatten()\n",
    "                min_ess = float(np.nanmin(ess_flat))\n",
    "            else:\n",
    "                # If it's already a scalar or array\n",
    "                min_ess = float(np.nanmin(ess))\n",
    "\n",
    "            print(f\"Maximum R-hat: {max_rhat:.4f}\")\n",
    "            print(f\"Minimum Effective Sample Size: {min_ess:.0f}\")\n",
    "            print()\n",
    "\n",
    "            # Convergence assessment\n",
    "            if max_rhat < 1.1:\n",
    "                print(\" R-hat indicates good convergence (< 1.1)\")\n",
    "            else:\n",
    "                print(\"R-hat indicates potential convergence issues (â‰¥ 1.1)\")\n",
    "                print(\"Consider running more iterations or increasing tune parameter\")\n",
    "\n",
    "            if min_ess > 400:\n",
    "                print(\" Effective sample size is adequate (> 400)\")\n",
    "            else:\n",
    "                print(\"Low effective sample size (â‰¤ 400)\")\n",
    "                print(\"Consider running more iterations\")\n",
    "\n",
    "            # Show detailed diagnostics for problematic parameters\n",
    "            if max_rhat >= 1.1 or min_ess <= 400:\n",
    "                print(f\"\\nProblematic parameters:\")\n",
    "\n",
    "                # Try to extract detailed information\n",
    "                try:\n",
    "                    # Convert to pandas for easier handling if possible\n",
    "                    if hasattr(rhat, 'to_dataframe'):\n",
    "                        rhat_df = rhat.to_dataframe().reset_index()\n",
    "                        ess_df = ess.to_dataframe().reset_index()\n",
    "\n",
    "                        # Find parameters with high R-hat\n",
    "                        try:\n",
    "                            value_col = [col for col in rhat_df.columns if col not in ['chain', 'draw']][-1]\n",
    "                            high_rhat = rhat_df[rhat_df[value_col] >= 1.1]\n",
    "                            if not high_rhat.empty:\n",
    "                                print(\"  High R-hat (â‰¥ 1.1):\")\n",
    "                                for _, row in high_rhat.head(10).iterrows():\n",
    "                                    param_info = [str(row[col]) for col in rhat_df.columns[:-1]]\n",
    "                                    print(f\"    {param_info}: {row[value_col]:.4f}\")\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                        # Find parameters with low ESS\n",
    "                        try:\n",
    "                            value_col = [col for col in ess_df.columns if col not in ['chain', 'draw']][-1]\n",
    "                            low_ess = ess_df[ess_df[value_col] <= 400]\n",
    "                            if not low_ess.empty:\n",
    "                                print(\"  Low ESS (â‰¤ 400):\")\n",
    "                                for _, row in low_ess.head(10).iterrows():\n",
    "                                    param_info = [str(row[col]) for col in ess_df.columns[:-1]]\n",
    "                                    print(f\"    {param_info}: {row[value_col]:.0f}\")\n",
    "                        except:\n",
    "                            pass\n",
    "                    else:\n",
    "                        # Fallback: just show summary statistics\n",
    "                        print(\"  Detailed parameter breakdown not available\")\n",
    "                        print(f\"  Overall: Max R-hat = {max_rhat:.4f}, Min ESS = {min_ess:.0f}\")\n",
    "\n",
    "                except Exception as detail_error:\n",
    "                    print(f\"  Could not extract detailed parameter information: {detail_error}\")\n",
    "                    print(f\"  Overall: Max R-hat = {max_rhat:.4f}, Min ESS = {min_ess:.0f}\")\n",
    "\n",
    "            print(f\"\\n{'='*60}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating convergence diagnostics: {e}\")\n",
    "            print(\"This might be due to the trace structure or variable names.\")\n",
    "\n",
    "            # Fallback: try to get basic diagnostics for key parameters only\n",
    "            try:\n",
    "                print(\"Attempting basic diagnostics for key parameters...\")\n",
    "                key_params = ['home_advantage']\n",
    "                if model_type == 'basic':\n",
    "                    key_params.extend(['mu_att', 'mu_def'])\n",
    "                else:\n",
    "                    key_params.extend(['mu_att_1', 'mu_att_2'])\n",
    "\n",
    "                # Filter to only available parameters\n",
    "                available_params = [p for p in key_params if p in trace.posterior.data_vars]\n",
    "\n",
    "                if available_params:\n",
    "                    basic_rhat = az.rhat(trace, var_names=available_params)\n",
    "                    basic_ess = az.ess(trace, var_names=available_params)\n",
    "\n",
    "                    print(f\"Basic diagnostics for {available_params}:\")\n",
    "                    for param in available_params:\n",
    "                        if param in basic_rhat.data_vars:\n",
    "                            param_rhat = float(basic_rhat[param].values)\n",
    "                            param_ess = float(basic_ess[param].values)\n",
    "                            status_rhat = \"\" if param_rhat < 1.1 else \"âš \"\n",
    "                            status_ess = \"\" if param_ess > 400 else \"âš \"\n",
    "                            print(f\"  {param}: R-hat = {param_rhat:.4f} {status_rhat}, ESS = {param_ess:.0f} {status_ess}\")\n",
    "\n",
    "            except Exception as fallback_error:\n",
    "                print(f\"Fallback diagnostics also failed: {fallback_error}\")\n",
    "                print(\"Convergence diagnostics could not be calculated for this model.\")\n",
    "\n",
    "    def plot_team_effect_traceplots(self, model_type='basic', team_names=None, n_teams=5):\n",
    "        \"\"\"\n",
    "        Plot trace plots specifically for team attack and defense effects\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_type : str\n",
    "            'basic' or 'mixture' to specify which model to plot\n",
    "        team_names : list, optional\n",
    "            Specific team names to plot. If None, plots first n_teams\n",
    "        n_teams : int\n",
    "            Number of teams to plot if team_names not specified\n",
    "        \"\"\"\n",
    "\n",
    "        trace = self.basic_trace if model_type == 'basic' else self.mixture_trace\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return\n",
    "\n",
    "        # Determine parameter names\n",
    "        if model_type == 'basic':\n",
    "            att_param = 'att'\n",
    "            def_param = 'def'\n",
    "        else:\n",
    "            att_param = 'att_centered'\n",
    "            def_param = 'def_centered'\n",
    "\n",
    "        # Check if parameters exist\n",
    "        if att_param not in trace.posterior.data_vars or def_param not in trace.posterior.data_vars:\n",
    "            print(f\"Team effect parameters not found in {model_type} model trace.\")\n",
    "            print(f\"Available variables: {list(trace.posterior.data_vars)}\")\n",
    "            return\n",
    "\n",
    "        # Select teams to plot\n",
    "        if team_names is None:\n",
    "            team_indices = list(range(min(n_teams, len(self.teams))))\n",
    "            selected_teams = [self.teams[i] for i in team_indices]\n",
    "        else:\n",
    "            team_indices = [self.teams.index(team) for team in team_names if team in self.teams]\n",
    "            selected_teams = team_names\n",
    "\n",
    "        if not team_indices:\n",
    "            print(\"No valid teams found for plotting.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nGenerating team effect trace plots for: {', '.join(selected_teams)}\")\n",
    "\n",
    "        # Create subplots\n",
    "        n_teams_plot = len(team_indices)\n",
    "        fig, axes = plt.subplots(n_teams_plot, 4, figsize=(16, 4*n_teams_plot))\n",
    "\n",
    "        if n_teams_plot == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "\n",
    "        for i, (team_idx, team_name) in enumerate(zip(team_indices, selected_teams)):\n",
    "            # Attack effect traces\n",
    "            att_samples = trace.posterior[att_param].isel({att_param + '_dim_0': team_idx})\n",
    "            def_samples = trace.posterior[def_param].isel({def_param + '_dim_0': team_idx})\n",
    "\n",
    "            # Plot traces for each chain\n",
    "            for chain in range(att_samples.sizes['chain']):\n",
    "                axes[i, 0].plot(att_samples.isel(chain=chain), alpha=0.7, label=f'Chain {chain}')\n",
    "                axes[i, 2].plot(def_samples.isel(chain=chain), alpha=0.7, label=f'Chain {chain}')\n",
    "\n",
    "            axes[i, 0].set_title(f'{team_name} - Attack Effect (Trace)')\n",
    "            axes[i, 0].set_ylabel('Attack Effect')\n",
    "            axes[i, 0].legend()\n",
    "            axes[i, 0].grid(True, alpha=0.3)\n",
    "\n",
    "            axes[i, 2].set_title(f'{team_name} - Defense Effect (Trace)')\n",
    "            axes[i, 2].set_ylabel('Defense Effect')\n",
    "            axes[i, 2].legend()\n",
    "            axes[i, 2].grid(True, alpha=0.3)\n",
    "\n",
    "            # Plot distributions\n",
    "            att_flat = att_samples.values.flatten()\n",
    "            def_flat = def_samples.values.flatten()\n",
    "\n",
    "            axes[i, 1].hist(att_flat, bins=50, alpha=0.7, density=True)\n",
    "            axes[i, 1].set_title(f'{team_name} - Attack Effect (Distribution)')\n",
    "            axes[i, 1].set_xlabel('Attack Effect')\n",
    "            axes[i, 1].set_ylabel('Density')\n",
    "            axes[i, 1].grid(True, alpha=0.3)\n",
    "\n",
    "            axes[i, 3].hist(def_flat, bins=50, alpha=0.7, density=True)\n",
    "            axes[i, 3].set_title(f'{team_name} - Defense Effect (Distribution)')\n",
    "            axes[i, 3].set_xlabel('Defense Effect')\n",
    "            axes[i, 3].set_ylabel('Density')\n",
    "            axes[i, 3].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.suptitle(f'Team Effects Trace Plots - {model_type.title()} Model', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def generate_all_traceplots(self, model_type='basic'):\n",
    "        \"\"\"\n",
    "        Generate comprehensive trace plots for model diagnostics\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_type : str\n",
    "            'basic' or 'mixture' to specify which model to plot\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"COMPREHENSIVE TRACE PLOT ANALYSIS - {model_type.upper()} MODEL\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        # 1. Main parameter trace plots\n",
    "        print(\"\\n1. Main Parameters Trace Plots:\")\n",
    "        self.plot_traceplots(model_type)\n",
    "\n",
    "        # 2. Team effects trace plots (for a subset of teams)\n",
    "        print(\"\\n2. Team Effects Trace Plots:\")\n",
    "        self.plot_team_effect_traceplots(model_type, n_teams=3)\n",
    "\n",
    "        # 3. Convergence diagnostics\n",
    "        print(\"\\n3. Convergence Diagnostics:\")\n",
    "        self.print_convergence_diagnostics(model_type)\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"TRACE PLOT ANALYSIS COMPLETE\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "    def print_extended_comparison_table(self, show_errors=True):\n",
    "        \"\"\"\n",
    "        Print a formatted comparison table with both basic and mixture models\n",
    "        Now includes wins, draws, and losses with REALISTIC simulation\n",
    "        \"\"\"\n",
    "\n",
    "        df = self.create_extended_comparison_table()\n",
    "        if df is None:\n",
    "            return\n",
    "\n",
    "        print(\"\\n\" + \"=\"*170)\n",
    "        print(\"EXTENDED SEASON RESULTS COMPARISON - OBSERVED vs BASIC vs MIXTURE MODELS\")\n",
    "        print(\"=\"*170)\n",
    "\n",
    "        # Check if mixture model results are available\n",
    "        has_mixture = 'mixture_points' in df.columns\n",
    "\n",
    "        # Print headers\n",
    "        if has_mixture:\n",
    "            print(f\"{'team':15} {'Observed results':^45} {'Basic model (medians)':^45} {'Mixture model (medians)':^45}\")\n",
    "            print(f\"{'':15} {'pts':>5} {'sc':>4} {'co':>4} {'W':>3} {'D':>3} {'L':>3} \" +\n",
    "                  f\"{'pts':>5} {'sc':>4} {'co':>4} {'W':>3} {'D':>3} {'L':>3} \" +\n",
    "                  f\"{'pts':>5} {'sc':>4} {'co':>4} {'W':>3} {'D':>3} {'L':>3}\")\n",
    "        else:\n",
    "            print(f\"{'team':15} {'Observed results':^45} {'Basic model (medians)':^45}\")\n",
    "            print(f\"{'':15} {'pts':>5} {'sc':>4} {'co':>4} {'W':>3} {'D':>3} {'L':>3} \" +\n",
    "                  f\"{'pts':>5} {'sc':>4} {'co':>4} {'W':>3} {'D':>3} {'L':>3}\")\n",
    "\n",
    "        print(\"-\" * 170)\n",
    "\n",
    "        # Print data rows\n",
    "        for _, row in df.iterrows():\n",
    "            print(f\"{row['team']:15}\", end=\"\")\n",
    "            # Observed\n",
    "            print(f\"{row['obs_points']:5d}\", end=\"\")\n",
    "            print(f\"{row['obs_scored']:4d}\", end=\"\")\n",
    "            print(f\"{row['obs_conceded']:4d}\", end=\"\")\n",
    "            print(f\"{row['obs_wins']:3d}\", end=\"\")\n",
    "            print(f\"{row['obs_draws']:3d}\", end=\"\")\n",
    "            print(f\"{row['obs_losses']:3d}\", end=\"\")\n",
    "            # Basic\n",
    "            print(f\"{row['basic_points']:5d}\", end=\"\")\n",
    "            print(f\"{row['basic_scored']:4d}\", end=\"\")\n",
    "            print(f\"{row['basic_conceded']:4d}\", end=\"\")\n",
    "            print(f\"{row['basic_wins']:3d}\", end=\"\")\n",
    "            print(f\"{row['basic_draws']:3d}\", end=\"\")\n",
    "            print(f\"{row['basic_losses']:3d}\", end=\"\")\n",
    "\n",
    "            if has_mixture:\n",
    "                # Mixture\n",
    "                print(f\"{row['mixture_points']:5d}\", end=\"\")\n",
    "                print(f\"{row['mixture_scored']:4d}\", end=\"\")\n",
    "                print(f\"{row['mixture_conceded']:4d}\", end=\"\")\n",
    "                print(f\"{row['mixture_wins']:3d}\", end=\"\")\n",
    "                print(f\"{row['mixture_draws']:3d}\", end=\"\")\n",
    "                print(f\"{row['mixture_losses']:3d}\", end=\"\")\n",
    "            print()\n",
    "\n",
    "        # Print summary statistics\n",
    "        if show_errors:\n",
    "            print(\"\\n\" + \"=\"*90)\n",
    "            print(\"MODEL PERFORMANCE COMPARISON - MEAN ABSOLUTE ERROR\")\n",
    "            print(\"=\"*90)\n",
    "\n",
    "            # Calculate mean absolute errors for basic model\n",
    "            basic_points_mae = np.mean(np.abs(df['obs_points'] - df['basic_points']))\n",
    "            basic_scored_mae = np.mean(np.abs(df['obs_scored'] - df['basic_scored']))\n",
    "            basic_conceded_mae = np.mean(np.abs(df['obs_conceded'] - df['basic_conceded']))\n",
    "            basic_wins_mae = np.mean(np.abs(df['obs_wins'] - df['basic_wins']))\n",
    "            basic_draws_mae = np.mean(np.abs(df['obs_draws'] - df['basic_draws']))\n",
    "            basic_losses_mae = np.mean(np.abs(df['obs_losses'] - df['basic_losses']))\n",
    "\n",
    "            print(f\"Basic Model Performance:\")\n",
    "            print(f\"  Points MAE:          {basic_points_mae:.2f}\")\n",
    "            print(f\"  Goals Scored MAE:    {basic_scored_mae:.2f}\")\n",
    "            print(f\"  Goals Conceded MAE:  {basic_conceded_mae:.2f}\")\n",
    "            print(f\"  Wins MAE:            {basic_wins_mae:.2f}\")\n",
    "            print(f\"  Draws MAE:           {basic_draws_mae:.2f}\")\n",
    "            print(f\"  Losses MAE:          {basic_losses_mae:.2f}\")\n",
    "            basic_total = (basic_points_mae + basic_scored_mae + basic_conceded_mae +\n",
    "                          basic_wins_mae + basic_draws_mae + basic_losses_mae)\n",
    "            print(f\"  Total MAE:           {basic_total:.2f}\")\n",
    "\n",
    "            if has_mixture:\n",
    "                mixture_points_mae = np.mean(np.abs(df['obs_points'] - df['mixture_points']))\n",
    "                mixture_scored_mae = np.mean(np.abs(df['obs_scored'] - df['mixture_scored']))\n",
    "                mixture_conceded_mae = np.mean(np.abs(df['obs_conceded'] - df['mixture_conceded']))\n",
    "                mixture_wins_mae = np.mean(np.abs(df['obs_wins'] - df['mixture_wins']))\n",
    "                mixture_draws_mae = np.mean(np.abs(df['obs_draws'] - df['mixture_draws']))\n",
    "                mixture_losses_mae = np.mean(np.abs(df['obs_losses'] - df['mixture_losses']))\n",
    "\n",
    "                print(f\"\\nMixture Model Performance:\")\n",
    "                print(f\"  Points MAE:          {mixture_points_mae:.2f}\")\n",
    "                print(f\"  Goals Scored MAE:    {mixture_scored_mae:.2f}\")\n",
    "                print(f\"  Goals Conceded MAE:  {mixture_conceded_mae:.2f}\")\n",
    "                print(f\"  Wins MAE:            {mixture_wins_mae:.2f}\")\n",
    "                print(f\"  Draws MAE:           {mixture_draws_mae:.2f}\")\n",
    "                print(f\"  Losses MAE:          {mixture_losses_mae:.2f}\")\n",
    "                mixture_total = (mixture_points_mae + mixture_scored_mae + mixture_conceded_mae +\n",
    "                               mixture_wins_mae + mixture_draws_mae + mixture_losses_mae)\n",
    "                print(f\"  Total MAE:           {mixture_total:.2f}\")\n",
    "\n",
    "                # Compare models\n",
    "                print(f\"\\n\" + \"=\"*60)\n",
    "                print(\"MODEL COMPARISON SUMMARY\")\n",
    "                print(\"=\"*60)\n",
    "\n",
    "                if basic_total < mixture_total:\n",
    "                    print(f\" BASIC MODEL WINS with lower total MAE ({basic_total:.2f} vs {mixture_total:.2f})\")\n",
    "                    improvement = ((mixture_total - basic_total) / mixture_total) * 100\n",
    "                    print(f\"   Basic model is {improvement:.1f}% better overall\")\n",
    "                else:\n",
    "                    print(f\" MIXTURE MODEL WINS with lower total MAE ({mixture_total:.2f} vs {basic_total:.2f})\")\n",
    "                    improvement = ((basic_total - mixture_total) / basic_total) * 100\n",
    "                    print(f\"   Mixture model is {improvement:.1f}% better overall\")\n",
    "\n",
    "                # Individual category winners\n",
    "                print(f\"\\nCategory Winners:\")\n",
    "                print(f\"  Points:   {'Basic' if basic_points_mae < mixture_points_mae else 'Mixture'} ({min(basic_points_mae, mixture_points_mae):.2f})\")\n",
    "                print(f\"  Scored:   {'Basic' if basic_scored_mae < mixture_scored_mae else 'Mixture'} ({min(basic_scored_mae, mixture_scored_mae):.2f})\")\n",
    "                print(f\"  Conceded: {'Basic' if basic_conceded_mae < mixture_conceded_mae else 'Mixture'} ({min(basic_conceded_mae, mixture_conceded_mae):.2f})\")\n",
    "                print(f\"  Wins:     {'Basic' if basic_wins_mae < mixture_wins_mae else 'Mixture'} ({min(basic_wins_mae, mixture_wins_mae):.2f})\")\n",
    "                print(f\"  Draws:    {'Basic' if basic_draws_mae < mixture_draws_mae else 'Mixture'} ({min(basic_draws_mae, mixture_draws_mae):.2f})\")\n",
    "                print(f\"  Losses:   {'Basic' if basic_losses_mae < mixture_losses_mae else 'Mixture'} ({min(basic_losses_mae, mixture_losses_mae):.2f})\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def detailed_model_analysis(self):\n",
    "        \"\"\"\n",
    "        Perform detailed analysis comparing both models (only if both are fitted)\n",
    "        Now includes wins, draws, and losses analysis\n",
    "        \"\"\"\n",
    "\n",
    "        df = self.create_extended_comparison_table()\n",
    "        if df is None or 'mixture_points' not in df.columns:\n",
    "            print(\"Both models need to be fitted for detailed comparison analysis.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(\"DETAILED MODEL DIFFERENCES ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # Calculate differences for all metrics\n",
    "        df['points_diff'] = df['mixture_points'] - df['basic_points']\n",
    "        df['scored_diff'] = df['mixture_scored'] - df['basic_scored']\n",
    "        df['conceded_diff'] = df['mixture_conceded'] - df['basic_conceded']\n",
    "        df['wins_diff'] = df['mixture_wins'] - df['basic_wins']\n",
    "        df['draws_diff'] = df['mixture_draws'] - df['basic_draws']\n",
    "        df['losses_diff'] = df['mixture_losses'] - df['basic_losses']\n",
    "\n",
    "        # Show teams where mixture model performs significantly better\n",
    "        print(\"\\nTeams where MIXTURE model predicts closer to observed results:\")\n",
    "        mixture_better = df[\n",
    "            (abs(df['obs_points'] - df['mixture_points']) < abs(df['obs_points'] - df['basic_points']))\n",
    "        ].copy()\n",
    "\n",
    "        if len(mixture_better) > 0:\n",
    "            mixture_better['basic_error'] = abs(mixture_better['obs_points'] - mixture_better['basic_points'])\n",
    "            mixture_better['mixture_error'] = abs(mixture_better['obs_points'] - mixture_better['mixture_points'])\n",
    "            mixture_better['improvement'] = mixture_better['basic_error'] - mixture_better['mixture_error']\n",
    "            mixture_better = mixture_better.sort_values('improvement', ascending=False)\n",
    "\n",
    "            for _, team in mixture_better.head(5).iterrows():\n",
    "                print(f\"  {team['team']:15}: Basic error {team['basic_error']:.1f}, Mixture error {team['mixture_error']:.1f} (improvement: {team['improvement']:.1f})\")\n",
    "        else:\n",
    "            print(\"  No teams found where mixture model significantly outperforms basic model\")\n",
    "\n",
    "        # Show teams where basic model performs significantly better\n",
    "        print(\"\\nTeams where BASIC model predicts closer to observed results:\")\n",
    "        basic_better = df[\n",
    "            (abs(df['obs_points'] - df['basic_points']) < abs(df['obs_points'] - df['mixture_points']))\n",
    "        ].copy()\n",
    "\n",
    "        if len(basic_better) > 0:\n",
    "            basic_better['basic_error'] = abs(basic_better['obs_points'] - basic_better['basic_points'])\n",
    "            basic_better['mixture_error'] = abs(basic_better['obs_points'] - basic_better['mixture_points'])\n",
    "            basic_better['improvement'] = basic_better['mixture_error'] - basic_better['basic_error']\n",
    "            basic_better = basic_better.sort_values('improvement', ascending=False)\n",
    "\n",
    "            for _, team in basic_better.head(5).iterrows():\n",
    "                print(f\"  {team['team']:15}: Mixture error {team['mixture_error']:.1f}, Basic error {team['basic_error']:.1f} (improvement: {team['improvement']:.1f})\")\n",
    "        else:\n",
    "            print(\"  No teams found where basic model significantly outperforms mixture model\")\n",
    "\n",
    "        # Show largest prediction differences between models\n",
    "        print(f\"\\nLargest differences between Basic and Mixture model predictions:\")\n",
    "        df['total_abs_diff'] = (abs(df['points_diff']) + abs(df['scored_diff']) + abs(df['conceded_diff']) +\n",
    "                               abs(df['wins_diff']) + abs(df['draws_diff']) + abs(df['losses_diff']))\n",
    "        biggest_diffs = df.nlargest(5, 'total_abs_diff')\n",
    "\n",
    "        for _, team in biggest_diffs.iterrows():\n",
    "            print(f\"  {team['team']:15}: Pts {team['points_diff']:+3.0f}, W {team['wins_diff']:+2.0f}, D {team['draws_diff']:+2.0f}, L {team['losses_diff']:+2.0f}\")\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"SUMMARY STATISTICS\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Teams where mixture model is better: {len(mixture_better)}\")\n",
    "        print(f\"Teams where basic model is better: {len(basic_better)}\")\n",
    "        print(f\"Average absolute difference in points: {abs(df['points_diff']).mean():.2f}\")\n",
    "        print(f\"Average absolute difference in goals scored: {abs(df['scored_diff']).mean():.2f}\")\n",
    "        print(f\"Average absolute difference in goals conceded: {abs(df['conceded_diff']).mean():.2f}\")\n",
    "        print(f\"Average absolute difference in wins: {abs(df['wins_diff']).mean():.2f}\")\n",
    "        print(f\"Average absolute difference in draws: {abs(df['draws_diff']).mean():.2f}\")\n",
    "        print(f\"Average absolute difference in losses: {abs(df['losses_diff']).mean():.2f}\")\n",
    "\n",
    "        # Correlation between observed and predicted for key metrics\n",
    "        basic_corr_points = df[['obs_points', 'basic_points']].corr().iloc[0,1]\n",
    "        mixture_corr_points = df[['obs_points', 'mixture_points']].corr().iloc[0,1]\n",
    "\n",
    "        basic_corr_wins = df[['obs_wins', 'basic_wins']].corr().iloc[0,1]\n",
    "        mixture_corr_wins = df[['obs_wins', 'mixture_wins']].corr().iloc[0,1]\n",
    "\n",
    "        print(f\"\\nCorrelation with observed results:\")\n",
    "        print(f\"Points - Basic: {basic_corr_points:.3f}, Mixture: {mixture_corr_points:.3f}\")\n",
    "        print(f\"Wins   - Basic: {basic_corr_wins:.3f}, Mixture: {mixture_corr_wins:.3f}\")\n",
    "        print(f\"Points winner: {'Mixture' if mixture_corr_points > basic_corr_points else 'Basic'} model\")\n",
    "        print(f\"Wins winner:   {'Mixture' if mixture_corr_wins > basic_corr_wins else 'Basic'} model\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    # ===== COMBINED ANALYSIS METHODS =====\n",
    "\n",
    "    def run_complete_analysis(self, draws_basic=250, draws_mixture=50, save_results=True, include_traceplots=True):\n",
    "        \"\"\"\n",
    "        Run complete analysis with both models including visualizations and comparisons\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"=\"*70)\n",
    "        print(\"COMPLETE BAYESIAN FOOTBALL MODEL ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # Fit basic model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"FITTING BASIC MODEL\")\n",
    "        print(\"=\"*50)\n",
    "        basic_trace = self.fit_basic_model(draws=draws_basic, tune=draws_basic, chains=4)\n",
    "\n",
    "        # Basic model analysis\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"BASIC MODEL ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "        self.print_model_summary('basic', show_all_teams=True)\n",
    "\n",
    "        # Plot basic model effects\n",
    "        self.plot_team_effects('basic')\n",
    "\n",
    "        # Generate trace plots for basic model\n",
    "        if include_traceplots:\n",
    "            #self.plot_traceplots('basic')\n",
    "            self.generate_all_traceplots('basic')\n",
    "\n",
    "        # Fit mixture model\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"FITTING MIXTURE MODEL\")\n",
    "        print(\"=\"*50)\n",
    "        try:\n",
    "            mixture_trace = self.fit_mixture_model(draws=draws_mixture, tune=draws_mixture, chains=4)\n",
    "            print(\" Mixture model fitted successfully!\")\n",
    "\n",
    "            # Mixture model analysis\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"MIXTURE MODEL ANALYSIS\")\n",
    "            print(\"=\"*50)\n",
    "            self.print_model_summary('mixture', show_all_teams=True)\n",
    "\n",
    "            # Plot mixture model effects\n",
    "            self.plot_team_effects('mixture')\n",
    "\n",
    "            # Generate trace plots for mixture model\n",
    "            if include_traceplots:\n",
    "                #self.plot_traceplots('mixture')\n",
    "                self.generate_all_traceplots('mixture')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Mixture model failed: {e}\")\n",
    "            print(\"Continuing with basic model only...\")\n",
    "\n",
    "        # Generate comparison tables\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"SEASON COMPARISON ANALYSIS\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        comparison_df = self.print_extended_comparison_table(show_errors=True)\n",
    "\n",
    "        # Detailed analysis if both models fitted\n",
    "        if self.mixture_trace is not None:\n",
    "            self.detailed_model_analysis()\n",
    "\n",
    "        # Save results\n",
    "        if save_results:\n",
    "            if comparison_df is not None:\n",
    "                filename = f\"football_analysis_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "                self.create_extended_comparison_table(save_to_file=True, filename=filename)\n",
    "                print(f\"\\n Results saved to: {filename}\")\n",
    "\n",
    "        # Example predictions\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"EXAMPLE MATCH PREDICTIONS\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Try some example predictions\n",
    "        example_matches = [\n",
    "            ('Internazionale', 'Milan'),\n",
    "            ('Roma', 'Lazio'),\n",
    "            ('Juventus', 'Napoli')\n",
    "        ]\n",
    "\n",
    "        for home, away in example_matches:\n",
    "            try:\n",
    "                # Basic model prediction\n",
    "                pred_basic = self.predict_match(home, away, 'basic')\n",
    "                if pred_basic:\n",
    "                    print(f\"\\n{home} vs {away} (Basic Model):\")\n",
    "                    print(f\"  Expected goals: {pred_basic['expected_home_goals']:.2f} - {pred_basic['expected_away_goals']:.2f}\")\n",
    "                    print(f\"  Probabilities: Home {pred_basic['prob_home_win']:.3f}, Draw {pred_basic['prob_draw']:.3f}, Away {pred_basic['prob_away_win']:.3f}\")\n",
    "\n",
    "                # Mixture model prediction (if available)\n",
    "                if self.mixture_trace is not None:\n",
    "                    pred_mixture = self.predict_match(home, away, 'mixture')\n",
    "                    if pred_mixture:\n",
    "                        print(f\"{home} vs {away} (Mixture Model):\")\n",
    "                        print(f\"  Expected goals: {pred_mixture['expected_home_goals']:.2f} - {pred_mixture['expected_away_goals']:.2f}\")\n",
    "                        print(f\"  Probabilities: Home {pred_mixture['prob_home_win']:.3f}, Draw {pred_mixture['prob_draw']:.3f}, Away {pred_mixture['prob_away_win']:.3f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Could not predict {home} vs {away}: {e}\")\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"ANALYSIS COMPLETE!\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        return {\n",
    "            'basic_trace': self.basic_trace,\n",
    "            'mixture_trace': self.mixture_trace,\n",
    "            'comparison_df': comparison_df\n",
    "        }\n",
    "\n",
    "# ===== USAGE EXAMPLE =====\n",
    "\n",
    "def run_example_analysis(data_file):\n",
    "    \"\"\"\n",
    "    Example function showing how to use the integrated model\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the model\n",
    "    print(\"Initializing Bayesian Football Model...\")\n",
    "    model = BayesianFootballModel(data_file)\n",
    "\n",
    "    # Run complete analysis\n",
    "    results = model.run_complete_analysis(\n",
    "        draws_basic=2500,    # Adjust based on your computational resources\n",
    "        draws_mixture=2000,   # Mixture model typically needs fewer draws\n",
    "        save_results=True,\n",
    "        include_traceplots=True  # Set to False if you don't want trace plots\n",
    "    )\n",
    "\n",
    "    return model, results\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"INTEGRATED BAYESIAN FOOTBALL MODEL\")\n",
    "    print(\"Combines Visualization + Comparison Tables + Predictions + Traceplots\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Replace with your actual file path\n",
    "    data_file = '/content/final dataset 2007-08.xlsx'\n",
    "\n",
    "    try:\n",
    "        # Run the complete analysis\n",
    "        model, results = run_example_analysis(data_file)\n",
    "\n",
    "        print(\"\\n SUCCESS! All analysis completed.\")\n",
    "        print(\"\\nYou can now use the model object to:\")\n",
    "        print(\"- model.predict_match('Team1', 'Team2', 'basic')\")\n",
    "        print(\"- model.plot_team_effects('mixture')\")\n",
    "        print(\"- model.print_model_summary('basic')\")\n",
    "        print(\"- model.create_extended_comparison_table()\")\n",
    "        #print(\"- model.plot_traceplots('basic')\")\n",
    "        print(\"- model.generate_all_traceplots('basic')\")\n",
    "        print(\"- model.plot_traceplots('mixture')\")\n",
    "        print(\"- model.plot_team_effect_traceplots('basic', ['Juventus', 'Milan'])\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error during analysis: {e}\")\n",
    "        print(\"Please check that your data file exists and has the correct format.\")\n",
    "        print(\"Required columns: hometeam_name, awayteam_name, y1, y2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqb0oWO6WG03"
   },
   "source": [
    "# Contribution - First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "04cb8d976e5a4d838b2b74569533c44b",
      "c2bda740154a4248b8128cbe528b0efc",
      "9b0068d86d9d4961bd157e0b282d5c54",
      "5ce73d25b865413eae29d6af689e2268",
      "3832043d90e0421f84d508f55a33a785",
      "15b2775d7e4648cba895b834d7cb79d2",
      "00648835c2ba47199a2bebcba0d220b9",
      "bbfeda0449d346f3ab78c073554feb41",
      "3ba9e78b18634f1db4b17fee9256dcda",
      "610b79b063584b298b0b6713cd684b8d",
      "3f8cc8eb364f4b2386a6798a2b055220",
      "213b9ed6586a4543818ecc964e927d34"
     ]
    },
    "id": "v9BYhScaWLTv",
    "outputId": "ca7ffcb6-7d55-4fdb-9bf4-0744d6f97ee2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BayesianFootballModel:\n",
    "    \"\"\"\n",
    "    Enhanced Bayesian hierarchical model for football match prediction\n",
    "    Based on Baio & Blangiardo (2010) paper with team-specific covariates\n",
    "\n",
    "    Includes stadium capacity, attendance, distance effects, and temporal factors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_file):\n",
    "        \"\"\"Initialize the model with data\"\"\"\n",
    "        print(f\"Initializing enhanced model with data file: {data_file}\")\n",
    "\n",
    "        # Initialize model attributes\n",
    "        self.basic_model = None\n",
    "        self.mixture_model = None\n",
    "        self.enhanced_model = None\n",
    "        self.full_covariate_model = None\n",
    "        self.basic_trace = None\n",
    "        self.mixture_trace = None\n",
    "        self.enhanced_trace = None\n",
    "        self.full_trace = None\n",
    "\n",
    "        try:\n",
    "            self.data = self.load_and_prepare_data(data_file)\n",
    "            print(\" Model initialization completed successfully\")\n",
    "            print(f\" Final check - n_games: {self.n_games}, n_teams: {self.n_teams}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error during model initialization: {e}\")\n",
    "            print(\"Please check that the data file exists and has the correct format\")\n",
    "            raise\n",
    "\n",
    "    def load_and_prepare_data(self, data_file):\n",
    "        \"\"\"Load and prepare the enhanced football data with all covariates\"\"\"\n",
    "\n",
    "        try:\n",
    "            # Try to read the new dataset\n",
    "            df = pd.read_excel('/data/dataset/dataset_2007-08_stadium_distance_date.xlsx')\n",
    "        except:\n",
    "            try:\n",
    "                df = pd.read_excel('/data/dataset/dataset_2007-08_stadium_distance_date.xlsx')\n",
    "            except:\n",
    "                # Fallback to basic dataset\n",
    "                df = pd.read_excel('/data/dataset/dataset_2007-08.xlsx')\n",
    "                print(\"Warning: Using basic dataset, creating sample covariates\")\n",
    "\n",
    "        # Clean column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "        # Check for required columns\n",
    "        required_cols = ['hometeam_name', 'awayteam_name', 'y1', 'y2']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Missing required columns: {missing_cols}\")\n",
    "            raise ValueError(f\"Dataset must contain columns: {required_cols}\")\n",
    "\n",
    "        # Create team mappings\n",
    "        all_teams = pd.concat([\n",
    "            df['hometeam_name'],\n",
    "            df['awayteam_name']\n",
    "        ]).unique()\n",
    "\n",
    "        team_to_id = {team: i for i, team in enumerate(sorted(all_teams))}\n",
    "        id_to_team = {i: team for team, i in team_to_id.items()}\n",
    "\n",
    "        # Map team names to consecutive IDs (0-based)\n",
    "        df['home_team_idx'] = df['hometeam_name'].map(team_to_id)\n",
    "        df['away_team_idx'] = df['awayteam_name'].map(team_to_id)\n",
    "\n",
    "        # Store basic team information\n",
    "        self.teams = sorted(all_teams)\n",
    "        self.n_teams = len(self.teams)\n",
    "        self.n_games = len(df)\n",
    "\n",
    "        print(f\"Data loaded: {self.n_games} games, {self.n_teams} teams\")\n",
    "\n",
    "        # Process and prepare covariates\n",
    "        self._prepare_covariates(df)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _prepare_covariates(self, df):\n",
    "        \"\"\"Prepare all covariates for modeling\"\"\"\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PREPARING COVARIATES\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # Initialize covariate dictionaries\n",
    "        self.team_covariates = {}\n",
    "        self.game_covariates = {}\n",
    "        self.standardized_team_covariates = {}\n",
    "        self.standardized_game_covariates = {}\n",
    "\n",
    "        # 1. STADIUM CHARACTERISTICS (team-specific)\n",
    "        self._prepare_stadium_covariates(df)\n",
    "\n",
    "        # 2. DISTANCE EFFECTS (game-specific)\n",
    "        self._prepare_distance_covariates(df)\n",
    "\n",
    "        # 3. TEMPORAL EFFECTS (game-specific)\n",
    "        self._prepare_temporal_covariates(df)\n",
    "\n",
    "        # 4. STANDARDIZE ALL COVARIATES\n",
    "        self._standardize_covariates()\n",
    "\n",
    "        print(\"\\n All covariates prepared successfully\")\n",
    "\n",
    "    def _prepare_stadium_covariates(self, df):\n",
    "        \"\"\"Prepare stadium-related covariates (team-specific)\"\"\"\n",
    "\n",
    "        print(\"\\n1. STADIUM CHARACTERISTICS:\")\n",
    "\n",
    "        # Check what stadium columns are available\n",
    "        stadium_cols = [col for col in df.columns if any(keyword in col.lower()\n",
    "                       for keyword in ['stadium', 'capacity', 'attendance', 'utilization'])]\n",
    "\n",
    "        print(f\"   Available stadium columns: {stadium_cols}\")\n",
    "\n",
    "        # Initialize team covariates dictionary\n",
    "        for i, team in enumerate(self.teams):\n",
    "            self.team_covariates[i] = {'team_name': team}\n",
    "\n",
    "        # Extract stadium information for each team\n",
    "        for team_idx, team in enumerate(self.teams):\n",
    "            # Get home games for this team\n",
    "            home_games = df[df['hometeam_name'] == team]\n",
    "\n",
    "            if len(home_games) > 0:\n",
    "                # Stadium capacity\n",
    "                if 'stadium_capacity' in df.columns:\n",
    "                    capacity = home_games['stadium_capacity'].iloc[0]\n",
    "                    self.team_covariates[team_idx]['stadium_capacity'] = float(capacity) if pd.notna(capacity) else 40000.0\n",
    "                else:\n",
    "                    # Create sample capacity based on team name (for demonstration)\n",
    "                    capacity = np.random.randint(20000, 80000)\n",
    "                    self.team_covariates[team_idx]['stadium_capacity'] = float(capacity)\n",
    "\n",
    "                # Average attendance\n",
    "                if 'average_attendance' in df.columns:\n",
    "                    avg_att = home_games['average_attendance'].mean()\n",
    "                    self.team_covariates[team_idx]['average_attendance'] = float(avg_att) if pd.notna(avg_att) else 30000.0\n",
    "                elif 'attendance' in df.columns:\n",
    "                    avg_att = home_games['attendance'].mean()\n",
    "                    self.team_covariates[team_idx]['average_attendance'] = float(avg_att) if pd.notna(avg_att) else 30000.0\n",
    "                else:\n",
    "                    # Sample attendance\n",
    "                    capacity = self.team_covariates[team_idx]['stadium_capacity']\n",
    "                    avg_att = capacity * np.random.uniform(0.4, 0.85)\n",
    "                    self.team_covariates[team_idx]['average_attendance'] = float(avg_att)\n",
    "\n",
    "                # Capacity utilization rate\n",
    "                if 'capacity_utilization' in df.columns:\n",
    "                    util = home_games['capacity_utilization'].mean()\n",
    "                    self.team_covariates[team_idx]['capacity_utilization'] = float(util) if pd.notna(util) else 0.75\n",
    "                else:\n",
    "                    # Calculate from attendance and capacity\n",
    "                    capacity = self.team_covariates[team_idx]['stadium_capacity']\n",
    "                    attendance = self.team_covariates[team_idx]['average_attendance']\n",
    "                    util = min(attendance / capacity, 1.0)\n",
    "                    self.team_covariates[team_idx]['capacity_utilization'] = float(util)\n",
    "\n",
    "      \n",
    "\n",
    "        print(f\"    Stadium characteristics prepared for {self.n_teams} teams\")\n",
    "\n",
    "        # Print summary statistics\n",
    "        capacities = [self.team_covariates[i]['stadium_capacity'] for i in range(self.n_teams)]\n",
    "        utilizations = [self.team_covariates[i]['capacity_utilization'] for i in range(self.n_teams)]\n",
    "\n",
    "        print(f\"   Stadium capacity range: {min(capacities):.0f} - {max(capacities):.0f}\")\n",
    "        print(f\"   Capacity utilization range: {min(utilizations):.3f} - {max(utilizations):.3f}\")\n",
    "\n",
    "    def _prepare_distance_covariates(self, df):\n",
    "        \"\"\"Prepare distance-related covariates (game-specific)\"\"\"\n",
    "\n",
    "        print(\"\\n2. DISTANCE EFFECTS:\")\n",
    "\n",
    "        # Check for distance columns\n",
    "        distance_cols = [col for col in df.columns if 'distance' in col.lower() or 'km' in col.lower()]\n",
    "        print(f\"   Available distance columns: {distance_cols}\")\n",
    "\n",
    "        if distance_cols and len(distance_cols) > 0:\n",
    "            # Use the first distance column found\n",
    "            distance_col = distance_cols[0]\n",
    "            distances = df[distance_col].values\n",
    "\n",
    "            # Handle missing values\n",
    "            distances = np.where(pd.isna(distances), np.median(distances[~pd.isna(distances)]), distances)\n",
    "\n",
    "            self.game_covariates['travel_distance'] = distances.astype(float)\n",
    "\n",
    "            print(f\"    Using column '{distance_col}' for travel distances\")\n",
    "            print(f\"   Distance range: {distances.min():.1f} - {distances.max():.1f} km\")\n",
    "\n",
    "\n",
    "            self.game_covariates['travel_distance'] = np.array(distances)\n",
    "            print(f\"    Sample distances created, range: {min(distances):.1f} - {max(distances):.1f} km\")\n",
    "\n",
    "    def _prepare_temporal_covariates(self, df):\n",
    "        \"\"\"Prepare temporal/seasonal covariates (game-specific)\"\"\"\n",
    "\n",
    "        print(\"\\n3. TEMPORAL EFFECTS:\")\n",
    "\n",
    "        # Check for date columns\n",
    "        date_cols = [col for col in df.columns if 'date' in col.lower() or 'weekday' in col.lower()]\n",
    "        print(f\"   Available date columns: {date_cols}\")\n",
    "\n",
    "        if date_cols and len(date_cols) > 0:\n",
    "            # Use the first date column\n",
    "            date_col = date_cols[0]\n",
    "\n",
    "            try:\n",
    "                # Try to parse dates\n",
    "                dates = pd.to_datetime(df[date_col])\n",
    "\n",
    "                # Extract temporal features\n",
    "                self.game_covariates['month'] = dates.dt.month.values\n",
    "                self.game_covariates['day_of_week'] = dates.dt.dayofweek.values  # 0=Monday\n",
    "                self.game_covariates['is_weekend'] = (dates.dt.dayofweek >= 5).astype(int).values\n",
    "\n",
    "                # Season phase (early, mid, late season)\n",
    "                months = dates.dt.month.values\n",
    "                season_phase = np.where(months <= 10, 0,  # Early season (Aug-Oct)\n",
    "                               np.where(months <= 2, 1,   # Mid season (Nov-Feb)\n",
    "                                       2))               # Late season (Mar-May)\n",
    "                self.game_covariates['season_phase'] = season_phase\n",
    "\n",
    "                print(f\"    Using column '{date_col}' for temporal effects\")\n",
    "                print(f\"   Date range: {dates.min()} to {dates.max()}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Warning: Could not parse dates from '{date_col}': {e}\")\n",
    "                self._create_sample_temporal_data()\n",
    "\n",
    "\n",
    "    def _standardize_covariates(self):\n",
    "        \"\"\"Standardize all covariates (z-score normalization)\"\"\"\n",
    "\n",
    "        print(\"\\n4. STANDARDIZING COVARIATES:\")\n",
    "\n",
    "        # Standardize team-specific covariates\n",
    "        team_cov_names = ['stadium_capacity', 'average_attendance', 'capacity_utilization']\n",
    "\n",
    "        for cov_name in team_cov_names:\n",
    "            if cov_name in [list(self.team_covariates[0].keys())][0]:\n",
    "                values = [self.team_covariates[i][cov_name] for i in range(self.n_teams)]\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values)\n",
    "\n",
    "                if std_val > 0:\n",
    "                    standardized_values = [(val - mean_val) / std_val for val in values]\n",
    "                else:\n",
    "                    standardized_values = [0.0] * len(values)\n",
    "\n",
    "                self.standardized_team_covariates[cov_name] = {\n",
    "                    'values': standardized_values,\n",
    "                    'mean': mean_val,\n",
    "                    'std': std_val\n",
    "                }\n",
    "\n",
    "                print(f\"   {cov_name}: mean={mean_val:.2f}, std={std_val:.2f}\")\n",
    "\n",
    "        # Standardize game-specific covariates\n",
    "        game_cov_names = ['travel_distance']\n",
    "\n",
    "        for cov_name in game_cov_names:\n",
    "            if cov_name in self.game_covariates:\n",
    "                values = self.game_covariates[cov_name]\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values)\n",
    "\n",
    "                if std_val > 0:\n",
    "                    standardized_values = (values - mean_val) / std_val\n",
    "                else:\n",
    "                    standardized_values = np.zeros_like(values)\n",
    "\n",
    "                self.standardized_game_covariates[cov_name] = {\n",
    "                    'values': standardized_values,\n",
    "                    'mean': mean_val,\n",
    "                    'std': std_val\n",
    "                }\n",
    "\n",
    "                print(f\"   {cov_name}: mean={mean_val:.2f}, std={std_val:.2f}\")\n",
    "\n",
    "        print(\"    All covariates standardized\")\n",
    "\n",
    "    def build_basic_model(self):\n",
    "        \"\"\"Build the basic hierarchical model (same as original)\"\"\"\n",
    "\n",
    "        print(\"Building basic hierarchical model...\")\n",
    "\n",
    "        # Prepare data arrays\n",
    "        home_team_idx = self.data['home_team_idx'].values\n",
    "        away_team_idx = self.data['away_team_idx'].values\n",
    "        y1_data = self.data['y1'].values\n",
    "        y2_data = self.data['y2'].values\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            # Home advantage parameter (fixed for all teams)\n",
    "            home_advantage = pm.Normal(\"home_advantage\", mu=0, tau=0.0001)\n",
    "\n",
    "            # Hyperparameters for attack and defense effects\n",
    "            mu_att = pm.Normal(\"mu_att\", mu=0, tau=0.0001)\n",
    "            mu_def = pm.Normal(\"mu_def\", mu=0, tau=0.0001)\n",
    "            tau_att = pm.Gamma(\"tau_att\", alpha=0.01, beta=0.01)\n",
    "            tau_def = pm.Gamma(\"tau_def\", alpha=0.01, beta=0.01)\n",
    "\n",
    "            # Team-specific attack and defense effects\n",
    "            att_star = pm.Normal(\"att_star\", mu=mu_att, tau=tau_att, shape=self.n_teams)\n",
    "            def_star = pm.Normal(\"def_star\", mu=mu_def, tau=tau_def, shape=self.n_teams)\n",
    "\n",
    "            # Sum-to-zero constraint\n",
    "            att = pm.Deterministic(\"att\", att_star - pt.mean(att_star))\n",
    "            def_ = pm.Deterministic(\"def\", def_star - pt.mean(def_star))\n",
    "\n",
    "            # Scoring intensities\n",
    "            log_theta_g1 = home_advantage + att[home_team_idx] + def_[away_team_idx]\n",
    "            log_theta_g2 = att[away_team_idx] + def_[home_team_idx]\n",
    "\n",
    "            theta_g1 = pm.Deterministic(\"theta_g1\", pt.exp(log_theta_g1))\n",
    "            theta_g2 = pm.Deterministic(\"theta_g2\", pt.exp(log_theta_g2))\n",
    "\n",
    "            # Likelihood\n",
    "            y1 = pm.Poisson(\"y1\", mu=theta_g1, observed=y1_data)\n",
    "            y2 = pm.Poisson(\"y2\", mu=theta_g2, observed=y2_data)\n",
    "\n",
    "        print(\" Basic model built successfully\")\n",
    "        self.basic_model = model\n",
    "        return model\n",
    "\n",
    "    def build_enhanced_stadium_model(self):\n",
    "        \"\"\"Build model with team-specific home advantage based on stadium characteristics\"\"\"\n",
    "\n",
    "        print(\"Building enhanced model with stadium-based home advantage...\")\n",
    "\n",
    "        # Prepare data arrays\n",
    "        home_team_idx = self.data['home_team_idx'].values\n",
    "        away_team_idx = self.data['away_team_idx'].values\n",
    "        y1_data = self.data['y1'].values\n",
    "        y2_data = self.data['y2'].values\n",
    "\n",
    "        # Prepare standardized stadium covariates\n",
    "        capacity_std = np.array(self.standardized_team_covariates['stadium_capacity']['values'])\n",
    "        utilization_std = np.array(self.standardized_team_covariates['capacity_utilization']['values'])\n",
    "        attendance_std = np.array(self.standardized_team_covariates['average_attendance']['values'])\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            # ========== TEAM-SPECIFIC HOME ADVANTAGE ==========\n",
    "\n",
    "            # Base home advantage\n",
    "            home_base = pm.Normal(\"home_base\", mu=0, tau=0.0001)\n",
    "\n",
    "            # Stadium effects on home advantage\n",
    "            beta_capacity = pm.Normal(\"beta_capacity\", mu=0, tau=0.001)\n",
    "            beta_utilization = pm.Normal(\"beta_utilization\", mu=0, tau=0.001)\n",
    "            beta_attendance = pm.Normal(\"beta_attendance\", mu=0, tau=0.001)\n",
    "\n",
    "            # Interaction between capacity and utilization\n",
    "            beta_interaction = pm.Normal(\"beta_interaction\", mu=0, tau=0.002)\n",
    "\n",
    "            # Team-specific home advantages\n",
    "            home_advantage_team = pm.Deterministic(\n",
    "                \"home_advantage_team\",\n",
    "                home_base +\n",
    "                beta_capacity * capacity_std +\n",
    "                beta_utilization * utilization_std +\n",
    "                beta_attendance * attendance_std +\n",
    "                beta_interaction * capacity_std * utilization_std\n",
    "            )\n",
    "\n",
    "            # ========== STANDARD TEAM EFFECTS ==========\n",
    "\n",
    "            mu_att = pm.Normal(\"mu_att\", mu=0, tau=0.0001)\n",
    "            mu_def = pm.Normal(\"mu_def\", mu=0, tau=0.0001)\n",
    "            tau_att = pm.Gamma(\"tau_att\", alpha=0.01, beta=0.01)\n",
    "            tau_def = pm.Gamma(\"tau_def\", alpha=0.01, beta=0.01)\n",
    "\n",
    "            att_star = pm.Normal(\"att_star\", mu=mu_att, tau=tau_att, shape=self.n_teams)\n",
    "            def_star = pm.Normal(\"def_star\", mu=mu_def, tau=tau_def, shape=self.n_teams)\n",
    "\n",
    "            att = pm.Deterministic(\"att\", att_star - pt.mean(att_star))\n",
    "            def_ = pm.Deterministic(\"def\", def_star - pt.mean(def_star))\n",
    "\n",
    "            # ========== SCORING INTENSITIES ==========\n",
    "\n",
    "            # Each game uses the home team's specific home advantage\n",
    "            log_theta_g1 = home_advantage_team[home_team_idx] + att[home_team_idx] + def_[away_team_idx]\n",
    "            log_theta_g2 = att[away_team_idx] + def_[home_team_idx]\n",
    "\n",
    "            theta_g1 = pm.Deterministic(\"theta_g1\", pt.exp(log_theta_g1))\n",
    "            theta_g2 = pm.Deterministic(\"theta_g2\", pt.exp(log_theta_g2))\n",
    "\n",
    "            y1 = pm.Poisson(\"y1\", mu=theta_g1, observed=y1_data)\n",
    "            y2 = pm.Poisson(\"y2\", mu=theta_g2, observed=y2_data)\n",
    "\n",
    "        print(\" Enhanced stadium model built successfully\")\n",
    "        self.enhanced_model = model\n",
    "        return model\n",
    "\n",
    "    def build_full_covariate_model(self):\n",
    "        \"\"\"Build comprehensive model with all covariates: stadium + distance + temporal\"\"\"\n",
    "\n",
    "        print(\"Building full covariate model with stadium, distance, and temporal effects...\")\n",
    "\n",
    "        # Prepare data arrays\n",
    "        home_team_idx = self.data['home_team_idx'].values\n",
    "        away_team_idx = self.data['away_team_idx'].values\n",
    "        y1_data = self.data['y1'].values\n",
    "        y2_data = self.data['y2'].values\n",
    "\n",
    "        # Prepare all standardized covariates\n",
    "        capacity_std = np.array(self.standardized_team_covariates['stadium_capacity']['values'])\n",
    "        utilization_std = np.array(self.standardized_team_covariates['capacity_utilization']['values'])\n",
    "        attendance_std = np.array(self.standardized_team_covariates['average_attendance']['values'])\n",
    "\n",
    "        distance_std = self.standardized_game_covariates['travel_distance']['values']\n",
    "        is_weekend = self.game_covariates['is_weekend']\n",
    "        season_phase = self.game_covariates['season_phase']\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            # ========== TEAM-SPECIFIC HOME ADVANTAGE ==========\n",
    "\n",
    "            home_base = pm.Normal(\"home_base\", mu=0, tau=0.0001)\n",
    "\n",
    "            # Stadium effects\n",
    "            beta_capacity = pm.Normal(\"beta_capacity\", mu=0, tau=0.001)\n",
    "            beta_utilization = pm.Normal(\"beta_utilization\", mu=0, tau=0.001)\n",
    "            beta_attendance = pm.Normal(\"beta_attendance\", mu=0, tau=0.001)\n",
    "            beta_capacity_util = pm.Normal(\"beta_capacity_util\", mu=0, tau=0.002)\n",
    "\n",
    "            # Team-specific home advantages (stadium-based)\n",
    "            home_advantage_team = pm.Deterministic(\n",
    "                \"home_advantage_team\",\n",
    "                home_base +\n",
    "                beta_capacity * capacity_std +\n",
    "                beta_utilization * utilization_std +\n",
    "                beta_attendance * attendance_std +\n",
    "                beta_capacity_util * capacity_std * utilization_std\n",
    "            )\n",
    "\n",
    "            # ========== GAME-SPECIFIC EFFECTS ==========\n",
    "\n",
    "            # Distance effect (reduces away team's performance)\n",
    "            beta_distance = pm.Normal(\"beta_distance\", mu=0, tau=0.002)\n",
    "            distance_effect = beta_distance * distance_std\n",
    "\n",
    "            # Temporal effects\n",
    "            beta_weekend = pm.Normal(\"beta_weekend\", mu=0, tau=0.002)\n",
    "            weekend_effect = beta_weekend * is_weekend\n",
    "\n",
    "            # Season phase effects (3 phases: early, mid, late)\n",
    "            beta_season = pm.Normal(\"beta_season\", mu=0, tau=0.002, shape=3)\n",
    "            season_effect = beta_season[season_phase]\n",
    "\n",
    "            # Combined game-specific home advantage\n",
    "            home_advantage_game = pm.Deterministic(\n",
    "                \"home_advantage_game\",\n",
    "                home_advantage_team[home_team_idx] +\n",
    "                distance_effect +  # Positive distance helps home team\n",
    "                weekend_effect +   # Weekend effect\n",
    "                season_effect      # Seasonal variation\n",
    "            )\n",
    "\n",
    "            # ========== DISTANCE EFFECTS ON AWAY TEAM ==========\n",
    "\n",
    "            # Distance fatigue reduces away team's attack and defense\n",
    "            beta_distance_att = pm.Normal(\"beta_distance_att\", mu=0, sigma=0.1)\n",
    "            beta_distance_def = pm.Normal(\"beta_distance_def\", mu=0, sigma=0.1)\n",
    "\n",
    "            distance_att_penalty = beta_distance_att * distance_std\n",
    "            distance_def_penalty = beta_distance_def * distance_std\n",
    "\n",
    "            # ========== STANDARD TEAM EFFECTS ==========\n",
    "\n",
    "            mu_att = pm.Normal(\"mu_att\", mu=0, tau=0.0001)\n",
    "            mu_def = pm.Normal(\"mu_def\", mu=0, tau=0.0001)\n",
    "            tau_att = pm.Gamma(\"tau_att\", alpha=0.01, beta=0.01)\n",
    "            tau_def = pm.Gamma(\"tau_def\", alpha=0.01, beta=0.01)\n",
    "\n",
    "            att_star = pm.Normal(\"att_star\", mu=mu_att, tau=tau_att, shape=self.n_teams)\n",
    "            def_star = pm.Normal(\"def_star\", mu=mu_def, tau=tau_def, shape=self.n_teams)\n",
    "\n",
    "            att = pm.Deterministic(\"att\", att_star - pt.mean(att_star))\n",
    "            def_ = pm.Deterministic(\"def\", def_star - pt.mean(def_star))\n",
    "\n",
    "            # ========== SCORING INTENSITIES ==========\n",
    "\n",
    "            # Home team scoring (with full home advantage)\n",
    "            log_theta_g1 = (home_advantage_game +\n",
    "                           att[home_team_idx] +\n",
    "                           def_[away_team_idx])\n",
    "\n",
    "            # Away team scoring (with distance penalties)\n",
    "            log_theta_g2 = (att[away_team_idx] + distance_att_penalty +  # Reduced attack due to travel\n",
    "                           def_[home_team_idx] + distance_def_penalty)   # Reduced defense due to travel\n",
    "\n",
    "            theta_g1 = pm.Deterministic(\"theta_g1\", pt.exp(log_theta_g1))\n",
    "            theta_g2 = pm.Deterministic(\"theta_g2\", pt.exp(log_theta_g2))\n",
    "\n",
    "            y1 = pm.Poisson(\"y1\", mu=theta_g1, observed=y1_data)\n",
    "            y2 = pm.Poisson(\"y2\", mu=theta_g2, observed=y2_data)\n",
    "\n",
    "        print(\" Full covariate model built successfully\")\n",
    "        self.full_covariate_model = model\n",
    "        return model\n",
    "\n",
    "    def fit_basic_model(self, draws=2000, tune=1000, chains=3, cores=1):\n",
    "        \"\"\"Fit the basic hierarchical model\"\"\"\n",
    "        print(\"Fitting basic hierarchical model...\")\n",
    "\n",
    "        if self.basic_model is None:\n",
    "            self.build_basic_model()\n",
    "\n",
    "        with self.basic_model:\n",
    "            self.basic_trace = pm.sample(\n",
    "                draws=draws, tune=tune, chains=chains, cores=cores,\n",
    "                random_seed=42,\n",
    "                return_inferencedata=True,\n",
    "                target_accept=0.95\n",
    "            )\n",
    "\n",
    "            # Sample posterior predictive\n",
    "            self.basic_trace.extend(pm.sample_posterior_predictive(self.basic_trace))\n",
    "\n",
    "        print(\"Basic model fitting completed!\")\n",
    "        return self.basic_trace\n",
    "\n",
    "    def fit_enhanced_model(self, draws=2000, tune=1000, chains=3, cores=1):\n",
    "        \"\"\"Fit the enhanced model with stadium covariates\"\"\"\n",
    "        print(\"Fitting enhanced model with stadium covariates...\")\n",
    "\n",
    "        if self.enhanced_model is None:\n",
    "            self.build_enhanced_stadium_model()\n",
    "\n",
    "        with self.enhanced_model:\n",
    "            self.enhanced_trace = pm.sample(\n",
    "                draws=draws, tune=tune, chains=chains, cores=cores,\n",
    "                random_seed=42, return_inferencedata=True, target_accept=0.9\n",
    "            )\n",
    "\n",
    "            self.enhanced_trace.extend(pm.sample_posterior_predictive(self.enhanced_trace))\n",
    "\n",
    "        print(\"Enhanced model fitting completed!\")\n",
    "        return self.enhanced_trace\n",
    "\n",
    "    def fit_full_model(self, draws=2000, tune=1000, chains=3, cores=1):\n",
    "        \"\"\"Fit the full covariate model\"\"\"\n",
    "        print(\"Fitting full covariate model...\")\n",
    "\n",
    "        if self.full_covariate_model is None:\n",
    "            self.build_full_covariate_model()\n",
    "\n",
    "        with self.full_covariate_model:\n",
    "            self.full_trace = pm.sample(\n",
    "                draws=draws, tune=tune, chains=chains, cores=cores,\n",
    "                random_seed=42, return_inferencedata=True, target_accept=0.9\n",
    "            )\n",
    "\n",
    "            self.full_trace.extend(pm.sample_posterior_predictive(self.full_trace))\n",
    "\n",
    "        print(\"Full covariate model fitting completed!\")\n",
    "        return self.full_trace\n",
    "\n",
    "    def check_convergence(self, trace, model_name=\"Model\"):\n",
    "        \"\"\"Comprehensive convergence diagnostics for MCMC chains\"\"\"\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"CONVERGENCE DIAGNOSTICS FOR {model_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # 1. R-hat diagnostics\n",
    "        try:\n",
    "            rhat = az.rhat(trace)\n",
    "            max_rhat = float(rhat.max())\n",
    "\n",
    "            print(f\"\\n1. R-HAT DIAGNOSTICS:\")\n",
    "            print(f\"   Max R-hat: {max_rhat:.4f}\")\n",
    "\n",
    "            if max_rhat < 1.01:\n",
    "                print(\"    EXCELLENT: All parameters have R-hat < 1.01\")\n",
    "            elif max_rhat < 1.1:\n",
    "                print(\"    GOOD: All parameters have R-hat < 1.1\")\n",
    "            else:\n",
    "                print(\"     WARNING: Some parameters have R-hat >= 1.1\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Error calculating R-hat: {e}\")\n",
    "\n",
    "        # 2. Effective Sample Size\n",
    "        try:\n",
    "            ess_bulk = az.ess(trace, kind=\"bulk\")\n",
    "            ess_tail = az.ess(trace, kind=\"tail\")\n",
    "\n",
    "            min_ess_bulk = float(ess_bulk.min())\n",
    "            min_ess_tail = float(ess_tail.min())\n",
    "\n",
    "            print(f\"\\n2. EFFECTIVE SAMPLE SIZE:\")\n",
    "            print(f\"   Min ESS (bulk): {min_ess_bulk:.0f}\")\n",
    "            print(f\"   Min ESS (tail): {min_ess_tail:.0f}\")\n",
    "\n",
    "            total_samples = trace.posterior.dims['draw'] * trace.posterior.dims['chain']\n",
    "            min_recommended = max(100, total_samples // 10)\n",
    "\n",
    "            if min_ess_bulk >= min_recommended and min_ess_tail >= min_recommended:\n",
    "                print(f\"    GOOD: ESS values above recommended minimum ({min_recommended})\")\n",
    "            else:\n",
    "                print(f\"     WARNING: Some ESS values below recommended minimum ({min_recommended})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Error calculating ESS: {e}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def analyze_covariate_effects(self, model_type='enhanced'):\n",
    "        \"\"\"Analyze the effects of covariates on home advantage and performance\"\"\"\n",
    "\n",
    "        if model_type == 'enhanced':\n",
    "            trace = self.enhanced_trace\n",
    "            model_name = \"Enhanced Stadium Model\"\n",
    "        elif model_type == 'full':\n",
    "            trace = self.full_trace\n",
    "            model_name = \"Full Covariate Model\"\n",
    "        else:\n",
    "            print(\"Please specify model_type as 'enhanced' or 'full'\")\n",
    "            return None\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_name} first!\")\n",
    "            return None\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"COVARIATE EFFECTS ANALYSIS - {model_name.upper()}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        # Stadium effects on home advantage\n",
    "        print(\"\\n1. STADIUM EFFECTS ON HOME ADVANTAGE:\")\n",
    "\n",
    "        stadium_effects = ['beta_capacity', 'beta_utilization', 'beta_attendance', 'beta_interaction']\n",
    "\n",
    "        for effect in stadium_effects:\n",
    "            if effect in trace.posterior.data_vars:\n",
    "                samples = trace.posterior[effect]\n",
    "                mean_val = float(samples.mean())\n",
    "                ci_low = float(samples.quantile(0.025))\n",
    "                ci_high = float(samples.quantile(0.975))\n",
    "\n",
    "                results[effect] = {\n",
    "                    'mean': mean_val,\n",
    "                    'ci_low': ci_low,\n",
    "                    'ci_high': ci_high,\n",
    "                    'significant': ci_low > 0 or ci_high < 0\n",
    "                }\n",
    "\n",
    "                significance = \" SIGNIFICANT\" if results[effect]['significant'] else \"â€¢ Not significant\"\n",
    "\n",
    "                print(f\"   {effect}: {mean_val:.4f} [{ci_low:.4f}, {ci_high:.4f}] {significance}\")\n",
    "\n",
    "        # Distance and temporal effects (if full model)\n",
    "        if model_type == 'full':\n",
    "            print(\"\\n2. DISTANCE EFFECTS:\")\n",
    "\n",
    "            distance_effects = ['beta_distance', 'beta_distance_att', 'beta_distance_def']\n",
    "\n",
    "            for effect in distance_effects:\n",
    "                if effect in trace.posterior.data_vars:\n",
    "                    samples = trace.posterior[effect]\n",
    "                    mean_val = float(samples.mean())\n",
    "                    ci_low = float(samples.quantile(0.025))\n",
    "                    ci_high = float(samples.quantile(0.975))\n",
    "\n",
    "                    results[effect] = {\n",
    "                        'mean': mean_val,\n",
    "                        'ci_low': ci_low,\n",
    "                        'ci_high': ci_high,\n",
    "                        'significant': ci_low > 0 or ci_high < 0\n",
    "                    }\n",
    "\n",
    "                    significance = \" SIGNIFICANT\" if results[effect]['significant'] else \"â€¢ Not significant\"\n",
    "                    print(f\"   {effect}: {mean_val:.4f} [{ci_low:.4f}, {ci_high:.4f}] {significance}\")\n",
    "\n",
    "            print(\"\\n3. TEMPORAL EFFECTS:\")\n",
    "\n",
    "            temporal_effects = ['beta_weekend', 'beta_season']\n",
    "\n",
    "            for effect in temporal_effects:\n",
    "                if effect in trace.posterior.data_vars:\n",
    "                    samples = trace.posterior[effect]\n",
    "\n",
    "                    if samples.ndim == 3:  # beta_season has multiple values\n",
    "                        for i in range(samples.shape[-1]):\n",
    "                            phase_samples = samples[..., i]\n",
    "                            mean_val = float(phase_samples.mean())\n",
    "                            ci_low = float(phase_samples.quantile(0.025))\n",
    "                            ci_high = float(phase_samples.quantile(0.975))\n",
    "\n",
    "                            phase_name = ['Early', 'Mid', 'Late'][i]\n",
    "                            significance = \" SIGNIFICANT\" if ci_low > 0 or ci_high < 0 else \"â€¢ Not significant\"\n",
    "\n",
    "                            print(f\"   {effect}[{phase_name}]: {mean_val:.4f} [{ci_low:.4f}, {ci_high:.4f}] {significance}\")\n",
    "                    else:\n",
    "                        mean_val = float(samples.mean())\n",
    "                        ci_low = float(samples.quantile(0.025))\n",
    "                        ci_high = float(samples.quantile(0.975))\n",
    "\n",
    "                        significance = \" SIGNIFICANT\" if ci_low > 0 or ci_high < 0 else \"â€¢ Not significant\"\n",
    "                        print(f\"   {effect}: {mean_val:.4f} [{ci_low:.4f}, {ci_high:.4f}] {significance}\")\n",
    "\n",
    "        # Team-specific home advantages\n",
    "        print(\"\\n4. TEAM-SPECIFIC HOME ADVANTAGES:\")\n",
    "\n",
    "        if 'home_advantage_team' in trace.posterior.data_vars:\n",
    "            home_team_effects = trace.posterior['home_advantage_team']\n",
    "            home_means = home_team_effects.mean(dim=['chain', 'draw']).values\n",
    "\n",
    "            # Create summary dataframe\n",
    "            home_df = pd.DataFrame({\n",
    "                'team': self.teams,\n",
    "                'home_advantage': home_means\n",
    "            })\n",
    "\n",
    "            # Add stadium characteristics\n",
    "            for i, team in enumerate(self.teams):\n",
    "                home_df.loc[i, 'capacity'] = self.team_covariates[i]['stadium_capacity']\n",
    "                home_df.loc[i, 'utilization'] = self.team_covariates[i]['capacity_utilization']\n",
    "                home_df.loc[i, 'attendance'] = self.team_covariates[i]['average_attendance']\n",
    "\n",
    "            home_df = home_df.sort_values('home_advantage', ascending=False)\n",
    "\n",
    "            print(\"\\n   Top 5 teams with highest home advantage:\")\n",
    "            print(home_df.head().round(4).to_string(index=False))\n",
    "\n",
    "            print(\"\\n   Bottom 5 teams with lowest home advantage:\")\n",
    "            print(home_df.tail().round(4).to_string(index=False))\n",
    "\n",
    "            results['team_home_advantages'] = home_df\n",
    "\n",
    "        return results\n",
    "\n",
    "    def plot_covariate_effects(self, model_type='enhanced'):\n",
    "        \"\"\"Create visualizations of covariate effects\"\"\"\n",
    "\n",
    "        if model_type == 'enhanced':\n",
    "            trace = self.enhanced_trace\n",
    "        elif model_type == 'full':\n",
    "            trace = self.full_trace\n",
    "        else:\n",
    "            print(\"Please specify model_type as 'enhanced' or 'full'\")\n",
    "            return\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Please fit the {model_type} model first!\")\n",
    "            return\n",
    "\n",
    "        # Determine number of subplots needed\n",
    "        if model_type == 'enhanced':\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "            axes = axes.flatten()\n",
    "        else:\n",
    "            fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "            axes = axes.flatten()\n",
    "\n",
    "        plot_idx = 0\n",
    "\n",
    "        # Plot 1: Stadium effects\n",
    "        stadium_effects = ['beta_capacity', 'beta_utilization', 'beta_attendance']\n",
    "\n",
    "        for effect in stadium_effects:\n",
    "            if effect in trace.posterior.data_vars and plot_idx < len(axes):\n",
    "                samples = trace.posterior[effect].values.flatten()\n",
    "                axes[plot_idx].hist(samples, bins=50, alpha=0.7, density=True)\n",
    "                axes[plot_idx].axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "                axes[plot_idx].set_title(f'{effect.replace(\"beta_\", \"\").title()} Effect')\n",
    "                axes[plot_idx].set_xlabel('Effect Size')\n",
    "                axes[plot_idx].set_ylabel('Density')\n",
    "                plot_idx += 1\n",
    "\n",
    "        # Plot: Team-specific home advantages vs stadium characteristics\n",
    "        if 'home_advantage_team' in trace.posterior.data_vars and plot_idx < len(axes):\n",
    "            home_advantages = trace.posterior['home_advantage_team'].mean(dim=['chain', 'draw']).values\n",
    "            utilizations = [self.team_covariates[i]['capacity_utilization'] for i in range(self.n_teams)]\n",
    "\n",
    "            axes[plot_idx].scatter(utilizations, home_advantages, alpha=0.7, s=60)\n",
    "            axes[plot_idx].set_xlabel('Capacity Utilization')\n",
    "            axes[plot_idx].set_ylabel('Home Advantage')\n",
    "            axes[plot_idx].set_title('Home Advantage vs Stadium Utilization')\n",
    "            axes[plot_idx].grid(True, alpha=0.3)\n",
    "\n",
    "            # Add team labels for extreme points\n",
    "            for i, team in enumerate(self.teams):\n",
    "                if home_advantages[i] > np.percentile(home_advantages, 80) or home_advantages[i] < np.percentile(home_advantages, 20):\n",
    "                    axes[plot_idx].annotate(team[:8], (utilizations[i], home_advantages[i]),\n",
    "                                          xytext=(3, 3), textcoords='offset points', fontsize=8)\n",
    "            plot_idx += 1\n",
    "\n",
    "        # Distance effects (full model only)\n",
    "        if model_type == 'full':\n",
    "            distance_effects = ['beta_distance', 'beta_distance_att']\n",
    "\n",
    "            for effect in distance_effects:\n",
    "                if effect in trace.posterior.data_vars and plot_idx < len(axes):\n",
    "                    samples = trace.posterior[effect].values.flatten()\n",
    "                    axes[plot_idx].hist(samples, bins=50, alpha=0.7, density=True)\n",
    "                    axes[plot_idx].axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "                    axes[plot_idx].set_title(f'{effect.replace(\"beta_\", \"\").replace(\"_\", \" \").title()} Effect')\n",
    "                    axes[plot_idx].set_xlabel('Effect Size')\n",
    "                    axes[plot_idx].set_ylabel('Density')\n",
    "                    plot_idx += 1\n",
    "\n",
    "        # Hide unused subplots\n",
    "        for i in range(plot_idx, len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def compare_all_models(self):\n",
    "        \"\"\"Compare all fitted models using information criteria and predictive accuracy\"\"\"\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        fitted_models = []\n",
    "        model_names = []\n",
    "\n",
    "        if self.basic_trace is not None:\n",
    "            fitted_models.append(('basic', self.basic_trace))\n",
    "            model_names.append('Basic')\n",
    "\n",
    "        if self.enhanced_trace is not None:\n",
    "            fitted_models.append(('enhanced', self.enhanced_trace))\n",
    "            model_names.append('Enhanced Stadium')\n",
    "\n",
    "        if self.full_trace is not None:\n",
    "            fitted_models.append(('full', self.full_trace))\n",
    "            model_names.append('Full Covariate')\n",
    "\n",
    "        if len(fitted_models) < 2:\n",
    "            print(\"Need at least 2 fitted models for comparison\")\n",
    "            return None\n",
    "\n",
    "        print(f\"\\n1. MODEL SELECTION CRITERIA:\")\n",
    "\n",
    "        model_comparison = {}\n",
    "\n",
    "        for model_name, trace in fitted_models:\n",
    "            try:\n",
    "                waic = az.waic(trace)\n",
    "                loo = az.loo(trace)\n",
    "\n",
    "                model_comparison[model_name] = {\n",
    "                    'waic': float(waic.waic),\n",
    "                    'waic_se': float(waic.se),\n",
    "                    'loo': float(loo.loo),\n",
    "                    'loo_se': float(loo.se)\n",
    "                }\n",
    "\n",
    "                print(f\"\\n   {model_name.upper()} MODEL:\")\n",
    "                print(f\"     WAIC: {model_comparison[model_name]['waic']:.2f} Â± {model_comparison[model_name]['waic_se']:.2f}\")\n",
    "                print(f\"     LOO:  {model_comparison[model_name]['loo']:.2f} Â± {model_comparison[model_name]['loo_se']:.2f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error calculating criteria for {model_name}: {e}\")\n",
    "\n",
    "        # Determine best models\n",
    "        if model_comparison:\n",
    "            best_waic = min(model_comparison.keys(), key=lambda x: model_comparison[x]['waic'])\n",
    "            best_loo = min(model_comparison.keys(), key=lambda x: model_comparison[x]['loo'])\n",
    "\n",
    "            print(f\"\\n    BEST MODEL BY WAIC: {best_waic.upper()}\")\n",
    "            print(f\"    BEST MODEL BY LOO:  {best_loo.upper()}\")\n",
    "\n",
    "        return model_comparison\n",
    "\n",
    "    def create_enhanced_comparison_table(self):\n",
    "        \"\"\"Create comparison table including all fitted models\"\"\"\n",
    "\n",
    "        if self.basic_trace is None:\n",
    "            print(\"Please fit at least the basic model first!\")\n",
    "            return None\n",
    "\n",
    "        # Calculate observed statistics\n",
    "        observed_stats = []\n",
    "\n",
    "        for team in self.teams:\n",
    "            team_data = self.data[\n",
    "                (self.data['hometeam_name'] == team) |\n",
    "                (self.data['awayteam_name'] == team)\n",
    "            ].copy()\n",
    "\n",
    "            points = 0\n",
    "            goals_scored = 0\n",
    "            goals_conceded = 0\n",
    "\n",
    "            for _, match in team_data.iterrows():\n",
    "                if match['hometeam_name'] == team:\n",
    "                    goals_for = match['y1']\n",
    "                    goals_against = match['y2']\n",
    "                    if goals_for > goals_against:\n",
    "                        points += 3\n",
    "                    elif goals_for == goals_against:\n",
    "                        points += 1\n",
    "                else:\n",
    "                    goals_for = match['y2']\n",
    "                    goals_against = match['y1']\n",
    "                    if goals_for > goals_against:\n",
    "                        points += 3\n",
    "                    elif goals_for == goals_against:\n",
    "                        points += 1\n",
    "\n",
    "                goals_scored += goals_for\n",
    "                goals_conceded += goals_against\n",
    "\n",
    "            observed_stats.append({\n",
    "                'team': team,\n",
    "                'obs_points': points,\n",
    "                'obs_scored': goals_scored,\n",
    "                'obs_conceded': goals_conceded\n",
    "            })\n",
    "\n",
    "        # Get predictions from each model\n",
    "        def get_model_predictions(trace, model_name):\n",
    "            if trace is None:\n",
    "                return None\n",
    "\n",
    "            try:\n",
    "                # Get posterior predictive samples\n",
    "                if 'y1' in trace.posterior_predictive.data_vars:\n",
    "                    y1_pred = trace.posterior_predictive['y1'].values\n",
    "                    y2_pred = trace.posterior_predictive['y2'].values\n",
    "                else:\n",
    "                    print(f\"No posterior predictive samples for {model_name}\")\n",
    "                    return None\n",
    "\n",
    "                # Calculate median predictions\n",
    "                y1_median = np.median(y1_pred, axis=(0, 1))\n",
    "                y2_median = np.median(y2_pred, axis=(0, 1))\n",
    "\n",
    "                pred_stats = []\n",
    "\n",
    "                for team in self.teams:\n",
    "                    team_indices = (\n",
    "                        (self.data['hometeam_name'] == team) |\n",
    "                        (self.data['awayteam_name'] == team)\n",
    "                    )\n",
    "                    team_games = self.data[team_indices].copy()\n",
    "\n",
    "                    points = 0\n",
    "                    goals_scored = 0\n",
    "                    goals_conceded = 0\n",
    "\n",
    "                    for _, match in team_games.iterrows():\n",
    "                        game_idx = match.name\n",
    "\n",
    "                        if match['hometeam_name'] == team:\n",
    "                            goals_for = y1_median[game_idx]\n",
    "                            goals_against = y2_median[game_idx]\n",
    "                        else:\n",
    "                            goals_for = y2_median[game_idx]\n",
    "                            goals_against = y1_median[game_idx]\n",
    "\n",
    "                        if goals_for > goals_against:\n",
    "                            points += 3\n",
    "                        elif abs(goals_for - goals_against) < 0.1:\n",
    "                            points += 1\n",
    "\n",
    "                        goals_scored += goals_for\n",
    "                        goals_conceded += goals_against\n",
    "\n",
    "                    pred_stats.append({\n",
    "                        'team': team,\n",
    "                        f'{model_name}_points': int(round(points)),\n",
    "                        f'{model_name}_scored': int(round(goals_scored)),\n",
    "                        f'{model_name}_conceded': int(round(goals_conceded))\n",
    "                    })\n",
    "\n",
    "                return pred_stats\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting predictions for {model_name}: {e}\")\n",
    "                return None\n",
    "\n",
    "        # Get predictions from all models\n",
    "        basic_preds = get_model_predictions(self.basic_trace, 'basic')\n",
    "        enhanced_preds = get_model_predictions(self.enhanced_trace, 'enhanced')\n",
    "        full_preds = get_model_predictions(self.full_trace, 'full')\n",
    "\n",
    "        # Combine all data\n",
    "        comparison_data = []\n",
    "        for i, obs in enumerate(observed_stats):\n",
    "            row = obs.copy()\n",
    "\n",
    "            if basic_preds:\n",
    "                row.update(basic_preds[i])\n",
    "            if enhanced_preds:\n",
    "                row.update(enhanced_preds[i])\n",
    "            if full_preds:\n",
    "                row.update(full_preds[i])\n",
    "\n",
    "            comparison_data.append(row)\n",
    "\n",
    "        df = pd.DataFrame(comparison_data)\n",
    "        df = df.sort_values('obs_points', ascending=False)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def print_enhanced_comparison_table(self):\n",
    "        \"\"\"Print formatted comparison table with all models\"\"\"\n",
    "\n",
    "        df = self.create_enhanced_comparison_table()\n",
    "        if df is None:\n",
    "            return None\n",
    "\n",
    "        print(f\"\\n{'='*140}\")\n",
    "        print(\"ENHANCED SEASON RESULTS COMPARISON - ALL MODELS\")\n",
    "        print(f\"{'='*140}\")\n",
    "\n",
    "        # Determine which models are available\n",
    "        has_enhanced = 'enhanced_points' in df.columns\n",
    "        has_full = 'full_points' in df.columns\n",
    "\n",
    "        # Print headers\n",
    "        header = f\"{'team':15} {'Observed':^20} {'Basic':^20}\"\n",
    "        if has_enhanced:\n",
    "            header += f\" {'Enhanced':^20}\"\n",
    "        if has_full:\n",
    "            header += f\" {'Full':^20}\"\n",
    "\n",
    "        print(header)\n",
    "\n",
    "        subheader = f\"{'':15} {'pts':>6} {'scored':>6} {'conceded':>6} {'pts':>6} {'scored':>6} {'conceded':>6}\"\n",
    "        if has_enhanced:\n",
    "            subheader += f\" {'pts':>6} {'scored':>6} {'conceded':>6}\"\n",
    "        if has_full:\n",
    "            subheader += f\" {'pts':>6} {'scored':>6} {'conceded':>6}\"\n",
    "\n",
    "        print(subheader)\n",
    "        print(\"-\" * 140)\n",
    "\n",
    "        # Print data rows\n",
    "        for _, row in df.iterrows():\n",
    "            line = f\"{row['team']:15}\"\n",
    "            line += f\"{row['obs_points']:6d}{row['obs_scored']:6d}{row['obs_conceded']:6d}\"\n",
    "            line += f\"{row['basic_points']:6d}{row['basic_scored']:6d}{row['basic_conceded']:6d}\"\n",
    "\n",
    "            if has_enhanced:\n",
    "                line += f\"{row['enhanced_points']:6d}{row['enhanced_scored']:6d}{row['enhanced_conceded']:6d}\"\n",
    "            if has_full:\n",
    "                line += f\"{row['full_points']:6d}{row['full_scored']:6d}{row['full_conceded']:6d}\"\n",
    "\n",
    "            print(line)\n",
    "\n",
    "        # Calculate and print MAE\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"MEAN ABSOLUTE ERROR COMPARISON\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        models = ['basic']\n",
    "        if has_enhanced:\n",
    "            models.append('enhanced')\n",
    "        if has_full:\n",
    "            models.append('full')\n",
    "\n",
    "        mae_results = {}\n",
    "\n",
    "        for model in models:\n",
    "            points_mae = np.mean(np.abs(df['obs_points'] - df[f'{model}_points']))\n",
    "            scored_mae = np.mean(np.abs(df['obs_scored'] - df[f'{model}_scored']))\n",
    "            conceded_mae = np.mean(np.abs(df['obs_conceded'] - df[f'{model}_conceded']))\n",
    "            total_mae = points_mae + scored_mae + conceded_mae\n",
    "\n",
    "            mae_results[model] = {\n",
    "                'points': points_mae,\n",
    "                'scored': scored_mae,\n",
    "                'conceded': conceded_mae,\n",
    "                'total': total_mae\n",
    "            }\n",
    "\n",
    "            print(f\"\\n{model.upper()} MODEL:\")\n",
    "            print(f\"  Points MAE:   {points_mae:.2f}\")\n",
    "            print(f\"  Scored MAE:   {scored_mae:.2f}\")\n",
    "            print(f\"  Conceded MAE: {conceded_mae:.2f}\")\n",
    "            print(f\"  Total MAE:    {total_mae:.2f}\")\n",
    "\n",
    "        # Find best model\n",
    "        best_model = min(mae_results.keys(), key=lambda x: mae_results[x]['total'])\n",
    "        print(f\"\\n BEST PREDICTIVE MODEL: {best_model.upper()}\")\n",
    "        print(f\"   Total MAE: {mae_results[best_model]['total']:.2f}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "# ===== ENHANCED USAGE EXAMPLES =====\n",
    "\n",
    "def run_enhanced_analysis(data_file):\n",
    "    \"\"\"\n",
    "    Run comprehensive analysis with all models\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"ENHANCED BAYESIAN FOOTBALL MODEL WITH COVARIATES\")\n",
    "    print(\"Stadium Capacity + Attendance + Distance + Temporal Effects\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Initialize model\n",
    "    model = BayesianFootballModel(data_file)\n",
    "\n",
    "    # Fit basic model\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FITTING BASIC MODEL\")\n",
    "    print(f\"{'='*60}\")\n",
    "    model.fit_basic_model(draws=1000, tune=1000, chains=4)\n",
    "    model.check_convergence(model.basic_trace, \"Basic Model\")\n",
    "\n",
    "    # Fit enhanced stadium model\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FITTING ENHANCED STADIUM MODEL\")\n",
    "    print(f\"{'='*60}\")\n",
    "    model.fit_enhanced_model(draws=1000, tune=1000, chains=4)\n",
    "    model.check_convergence(model.enhanced_trace, \"Enhanced Stadium Model\")\n",
    "\n",
    "    # Analyze stadium effects\n",
    "    model.analyze_covariate_effects('enhanced')\n",
    "    model.plot_covariate_effects('enhanced')\n",
    "\n",
    "    # Fit full covariate model\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FITTING FULL COVARIATE MODEL\")\n",
    "    print(f\"{'='*60}\")\n",
    "    try:\n",
    "        model.fit_full_model(draws=1000, tune=1000, chains=4)\n",
    "        model.check_convergence(model.full_trace, \"Full Covariate Model\")\n",
    "\n",
    "        # Analyze all effects\n",
    "        model.analyze_covariate_effects('full')\n",
    "        model.plot_covariate_effects('full')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Full model failed: {e}\")\n",
    "        print(\"Continuing with basic and enhanced models...\")\n",
    "\n",
    "    # Compare all models\n",
    "    model.compare_all_models()\n",
    "    model.print_enhanced_comparison_table()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"ENHANCED BAYESIAN FOOTBALL MODEL\")\n",
    "    print(\"With Stadium, Distance, and Temporal Covariates\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Use the new dataset\n",
    "    data_file = 'data/dataset/dataset_2007-08_stadium_distance_date.xlsx.xlsx'\n",
    "\n",
    "    try:\n",
    "        model = run_enhanced_analysis(data_file)\n",
    "\n",
    "        print(f\"\\n SUCCESS! Enhanced analysis completed.\")\n",
    "        print(f\"\\nAvailable methods:\")\n",
    "        print(f\"- model.analyze_covariate_effects('enhanced' or 'full')\")\n",
    "        print(f\"- model.plot_covariate_effects('enhanced' or 'full')\")\n",
    "        print(f\"- model.compare_all_models()\")\n",
    "        print(f\"- model.print_enhanced_comparison_table()\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error during analysis: {e}\")\n",
    "        print(\"Please check that your data file exists and has the correct format.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yUXn2iC2RVFH",
    "Bz9q5TjZoExa",
    "vqb0oWO6WG03"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
